
# Post \#75299523 [Link](https://stackoverflow.com/questions/75299523/)

## How to handle arrays of extremely large strings in C#

**Vote**: 2 (631/702) **Views**: 294 (702/702) 

**Internal ID** \#2-6-410

Created at 2023-01-31 15:38:57

Tags: `c#` `arrays` `memory-management` `out-of-memory` `floyd-warshall`

----------

#### Metadata:

Area: `Back-end`

Language: `c#` (full parsed tag list: `c#`)

----------

**Notepad**


----------

I'm implementing the Floyd-Warshal algorithm, as can be found [here](https://www.geeksforgeeks.org/floyd-warshall-algorithm-dp-16).
I'm not just interested in the shortest distance between nodes, but also in the path, corresponding with that distance.
In order to do this, I have modified the algorithm as follows:
```
double[,] dist = new double[V, V];        // existing line
string[,] connections = new string[V, V]; // new line, needed for remembering the path

...
for (i = 0; i < V; i++){
  for (j = 0; j < V; j++){
    dist[i, j] = graph[i, j];
    connections[i, j] = $"({i},{j})";}} // added: initialisation of "connections"

...
if (dist[i, k] + dist[k, j] < dist[i, j])
{
  dist[i, j] = dist[i, k] + dist[k, j];
  connections[i, j] = connections[i, k] + "-" + connections[k, j]; // Added for remembering shortest path
}
```

I'm running this algorithm with a snake-like list of locations of one million, all of them simply being added one after the other.
As a result, my `connections` array looks as follows:
```
[0, 0]  "(0,0)"
    [0, 1]  "(0,1)"
    [0, 2]  "(0,1)-(1,2)"
    [0, 3]  "(0,1)-(1,2)-(2,3)"
    [0, 4]  "(0,1)-(1,2)-(2,3)-(3,4)"
    [0, 5]  "(0,1)-(1,2)-(2,3)-(3,4)-(4,5)"
    ...
    [0, 787]  "(0,1)-(1,2)-...(786,787)" // length of +7000 characters
    ...
```

... at the moment of my `OutOfMemoryException` (what a surprise) :-)
I would like to avoid that `OutOfMemoryException`, and start thinking of different techniques:
- - 
I believe the second option being the most realistic (don't kill me if I'm wrong) :-)
Is there a technique in C# which makes that possible?
Oh, if you react like "", don't refrain from telling me how :-)

In the meantime, I've replaced my strings  with `List`s of `List`s of `Point`s, and this seems to be working fine:
Instead of:
```
string[,] l_connections;
```

I have:
```
List<List<List<Point>>> l_connections;
```

The speed has doubled, and when working with huge collections of dictionaries (+1000 entries of ...), I get a `System.OutOfMemoryException` only at ±800 entries instead of ±650.
That's already a huge improvement, but does anybody know to get even better?

There is following GC and GCSettings information:
```
System.GC.MaxGeneration:[2]
IsServerGC:[False]
LargeObjectHeapCompactionMode:[Default]
LatencyMode:[Interactive]
```

I have altered the `LargeObjectHeapCompactionMode` to `CompactOnce` but this brought the performance back to similar results as when I was working with large strings instead of `List`s.

Hereby the code, when working with `List` collections:
```
public void floydWarshall(Dictionary<(int x, int y), double> dictionary, out double[,] dist, out List<List<List<Point>>> connections)
{
    int dictionary_size = (int)Math.Ceiling(Math.Sqrt(dictionary.Count));
    dist = new double[dictionary_size, dictionary_size];
...

    for (k = 0; k < dictionary_size; k++)
    {
        // Pick all vertices as source one by one
        for (i = 0; i < dictionary_size; i++)
        {
            // Pick all vertices as destination for the above picked source
            for (j = 0; j < dictionary_size; j++)
            {
                // If vertex k is on the shortest path from i to j, then update dist[i][j]
                if (dist[i, k] + dist[k, j] < dist[i, j])
                {
                    dist[i, j] = dist[i, k] + dist[k, j];
                    connections[i][j] =  new List<Point>();
                    connections[i][j].AddRange(connections[i][k]);
                    connections[i][j].AddRange(connections[k][j]);
                 }
            }
        }
    }
```

Thanks in advance


----------
        
## GPT4 Attempt \#0

The Floyd-Warshall algorithm has a time complexity of O(V^3) and space complexity of O(V^2), where V is the number of vertices. When you have a large number of vertices (like 1 million), the algorithm will consume a lot of memory and time. 

In your case, you are trying to store the path information in addition to the distance information. This increases the memory usage significantly, especially when you are dealing with a large graph. 

Your approach of using `List<List<List<Point>>>` to store the path information is a good one, as it avoids the overhead of string concatenation and reduces the memory usage. However, it still consumes a lot of memory when the graph is large.

Here are a few suggestions to further optimize your code:

1. **Use an adjacency list instead of an adjacency matrix**: If your graph is sparse (i.e., the number of edges is much less than V^2), you can use an adjacency list to represent the graph. This can significantly reduce the memory usage.

2. **Store only the next vertex on the shortest path**: Instead of storing the entire path from i to j, you can store only the next vertex on the shortest path from i to j. This reduces the memory usage from O(V^2) to O(V). To retrieve the entire path, you can start from vertex i and follow the next vertices until you reach vertex j.

3. **Use a more memory-efficient data structure**: Instead of `List<List<List<Point>>>`, you can use a more memory-efficient data structure to store the path information. For example, you can use an array of linked lists, where each linked list represents a path.

4. **Use a more efficient algorithm**: If you only need the shortest path between a pair of vertices, you can use Dijkstra's algorithm, which has a lower time complexity (O(V^2) or O(E log V) with a priority queue) and requires less memory.

5. **Increase the memory limit of your application**: If you are running a 32-bit application, it can only use up to 2 GB of memory. By switching to a 64-bit application, you can use more memory. However, this is only a temporary solution and may not be feasible if your graph continues to grow.

6. **Use a database**: If your graph is too large to fit into memory, you can store it in a database and perform the algorithm on the database. This will be slower than performing the algorithm in memory, but it allows you to handle very large graphs.

--------

## GPT4 Attempt \#1

The Floyd-Warshall algorithm has a time and space complexity of O(V^3), where V is the number of vertices in the graph. This means that the algorithm can quickly become inefficient for large graphs. 

In your case, you are trying to store the path information for each pair of vertices in a 2D array. This can lead to a significant increase in memory usage, especially for large graphs, as you have observed.

One way to reduce the memory usage is to not store the entire path for each pair of vertices, but instead store only the next vertex on the shortest path from each vertex to every other vertex. This is often referred to as the "next-hop" information.

Here is a modified version of your Floyd-Warshall algorithm that implements this idea:

```csharp
public void floydWarshall(Dictionary<(int x, int y), double> dictionary, out double[,] dist, out int[,] next)
{
    int dictionary_size = (int)Math.Ceiling(Math.Sqrt(dictionary.Count));
    dist = new double[dictionary_size, dictionary_size];
    next = new int[dictionary_size, dictionary_size];

    // Initialize dist and next arrays
    for (int i = 0; i < dictionary_size; i++)
    {
        for (int j = 0; j < dictionary_size; j++)
        {
            if (i == j)
            {
                dist[i, j] = 0;
                next[i, j] = j;
            }
            else if (dictionary.ContainsKey((i, j)))
            {
                dist[i, j] = dictionary[(i, j)];
                next[i, j] = j;
            }
            else
            {
                dist[i, j] = double.PositiveInfinity;
                next[i, j] = -1;
            }
        }
    }

    // Floyd-Warshall algorithm
    for (int k = 0; k < dictionary_size; k++)
    {
        for (int i = 0; i < dictionary_size; i++)
        {
            for (int j = 0; j < dictionary_size; j++)
            {
                if (dist[i, k] + dist[k, j] < dist[i, j])
                {
                    dist[i, j] = dist[i, k] + dist[k, j];
                    next[i, j] = next[i, k];
                }
            }
        }
    }
}
```

With this modification, you can reconstruct the shortest path from any vertex i to any vertex j by starting at vertex i, then repeatedly moving to the next vertex on the path until you reach vertex j. This can be done with a simple loop:

```csharp
public List<int> getShortestPath(int i, int j, int[,] next)
{
    List<int> path = new List<int>();
    if (next[i, j] == -1)
    {
        return path; // no path exists
    }
    path.Add(i);
    while (i != j)
    {
        i = next[i, j];
        path.Add(i);
    }
    return path;
}
```

This approach significantly reduces the memory usage of the algorithm, as you are only storing one integer for each pair of vertices, instead of a potentially large list of vertices. However, it does require an additional step to reconstruct the shortest path when needed.

--------

## GPT4 Attempt \#2

The Floyd-Warshall algorithm has a time complexity of O(V^3) and space complexity of O(V^2). When you have a large number of vertices (like a million), it's not surprising that you're running out of memory, especially when you're trying to store all the paths.

Instead of storing all the paths, you can store only the next vertex on the shortest path from each vertex to every other vertex. This will reduce the space complexity from O(V^3) to O(V^2).

Here is a modified version of your code:

```csharp
public void floydWarshall(Dictionary<(int x, int y), double> dictionary, out double[,] dist, out int[,] next)
{
    int dictionary_size = (int)Math.Ceiling(Math.Sqrt(dictionary.Count));
    dist = new double[dictionary_size, dictionary_size];
    next = new int[dictionary_size, dictionary_size];
    ...

    for (k = 0; k < dictionary_size; k++)
    {
        for (i = 0; i < dictionary_size; i++)
        {
            for (j = 0; j < dictionary_size; j++)
            {
                if (dist[i, k] + dist[k, j] < dist[i, j])
                {
                    dist[i, j] = dist[i, k] + dist[k, j];
                    next[i, j] = next[i, k];
                }
            }
        }
    }
}
```

In the `next` matrix, `next[i, j]` is the next vertex on the shortest path from `i` to `j`. If there is no path from `i` to `j`, `next[i, j]` is -1.

To get the shortest path from `i` to `j`, you can start at `i`, go to `next[i, j]`, then go to `next[next[i, j], j]`, and so on, until you reach `j`.

This approach significantly reduces the amount of memory needed to store the paths. However, it still requires O(V^3) time to compute the shortest paths, which may be prohibitive for large graphs. If you need to compute shortest paths in large graphs, you may need to use a different algorithm, such as Dijkstra's algorithm with a priority queue, which has a time complexity of O(E + V log V), where E is the number of edges.

--------
