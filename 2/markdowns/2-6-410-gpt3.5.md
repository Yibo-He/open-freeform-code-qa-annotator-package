
# Post \#75299523 [Link](https://stackoverflow.com/questions/75299523/)

## How to handle arrays of extremely large strings in C#

**Vote**: 2 (631/702) **Views**: 294 (702/702) 

**Internal ID** \#2-6-410

Created at 2023-01-31 15:38:57

Tags: `c#` `arrays` `memory-management` `out-of-memory` `floyd-warshall`

----------

#### Metadata:

Area: `Back-end`

Language: `c#` (full parsed tag list: `c#`)

----------

**Notepad**


----------

I'm implementing the Floyd-Warshal algorithm, as can be found [here](https://www.geeksforgeeks.org/floyd-warshall-algorithm-dp-16).
I'm not just interested in the shortest distance between nodes, but also in the path, corresponding with that distance.
In order to do this, I have modified the algorithm as follows:
```
double[,] dist = new double[V, V];        // existing line
string[,] connections = new string[V, V]; // new line, needed for remembering the path

...
for (i = 0; i < V; i++){
  for (j = 0; j < V; j++){
    dist[i, j] = graph[i, j];
    connections[i, j] = $"({i},{j})";}} // added: initialisation of "connections"

...
if (dist[i, k] + dist[k, j] < dist[i, j])
{
  dist[i, j] = dist[i, k] + dist[k, j];
  connections[i, j] = connections[i, k] + "-" + connections[k, j]; // Added for remembering shortest path
}
```

I'm running this algorithm with a snake-like list of locations of one million, all of them simply being added one after the other.
As a result, my `connections` array looks as follows:
```
[0, 0]  "(0,0)"
    [0, 1]  "(0,1)"
    [0, 2]  "(0,1)-(1,2)"
    [0, 3]  "(0,1)-(1,2)-(2,3)"
    [0, 4]  "(0,1)-(1,2)-(2,3)-(3,4)"
    [0, 5]  "(0,1)-(1,2)-(2,3)-(3,4)-(4,5)"
    ...
    [0, 787]  "(0,1)-(1,2)-...(786,787)" // length of +7000 characters
    ...
```

... at the moment of my `OutOfMemoryException` (what a surprise) :-)
I would like to avoid that `OutOfMemoryException`, and start thinking of different techniques:
- - 
I believe the second option being the most realistic (don't kill me if I'm wrong) :-)
Is there a technique in C# which makes that possible?
Oh, if you react like "", don't refrain from telling me how :-)

In the meantime, I've replaced my strings  with `List`s of `List`s of `Point`s, and this seems to be working fine:
Instead of:
```
string[,] l_connections;
```

I have:
```
List<List<List<Point>>> l_connections;
```

The speed has doubled, and when working with huge collections of dictionaries (+1000 entries of ...), I get a `System.OutOfMemoryException` only at ±800 entries instead of ±650.
That's already a huge improvement, but does anybody know to get even better?

There is following GC and GCSettings information:
```
System.GC.MaxGeneration:[2]
IsServerGC:[False]
LargeObjectHeapCompactionMode:[Default]
LatencyMode:[Interactive]
```

I have altered the `LargeObjectHeapCompactionMode` to `CompactOnce` but this brought the performance back to similar results as when I was working with large strings instead of `List`s.

Hereby the code, when working with `List` collections:
```
public void floydWarshall(Dictionary<(int x, int y), double> dictionary, out double[,] dist, out List<List<List<Point>>> connections)
{
    int dictionary_size = (int)Math.Ceiling(Math.Sqrt(dictionary.Count));
    dist = new double[dictionary_size, dictionary_size];
...

    for (k = 0; k < dictionary_size; k++)
    {
        // Pick all vertices as source one by one
        for (i = 0; i < dictionary_size; i++)
        {
            // Pick all vertices as destination for the above picked source
            for (j = 0; j < dictionary_size; j++)
            {
                // If vertex k is on the shortest path from i to j, then update dist[i][j]
                if (dist[i, k] + dist[k, j] < dist[i, j])
                {
                    dist[i, j] = dist[i, k] + dist[k, j];
                    connections[i][j] =  new List<Point>();
                    connections[i][j].AddRange(connections[i][k]);
                    connections[i][j].AddRange(connections[k][j]);
                 }
            }
        }
    }
```

Thanks in advance


----------
        
## GPT3.5 Attempt \#0

It seems like you have already made some good progress in optimizing your code by using `List`s instead of strings to store the path. Here are a few additional suggestions:

1. Use a sparse matrix

If your graph is sparse (i.e. it has many zero entries), you can use a sparse matrix data structure to reduce memory usage. A sparse matrix only stores the non-zero entries, which can be much more memory-efficient than a dense matrix. There are several libraries available in C# for working with sparse matrices, such as Math.NET Numerics and Extreme Optimization.

2. Use a compressed path representation

Instead of storing the entire path as a list of points, you can use a compressed representation that only stores the necessary information to reconstruct the path. For example, you could store the indices of the nodes along the path instead of their coordinates. This can significantly reduce memory usage, especially for long paths.

3. Use a streaming approach

If your graph is too large to fit into memory, you can use a streaming approach where you only load a portion of the graph into memory at a time. For example, you could divide the graph into smaller subgraphs and run the Floyd-Warshall algorithm on each subgraph separately. Then, you can combine the results to get the shortest paths for the entire graph. This approach requires more computation time, but it can handle graphs that are too large to fit into memory.

4. Use a different algorithm

If the Floyd-Warshall algorithm is still too memory-intensive, you can consider using a different algorithm that is more memory-efficient. For example, Dijkstra's algorithm or A* algorithm can be used to find the shortest path between two nodes in a graph, and they only require storing the shortest path to each node, rather than the shortest path between all pairs of nodes. However, these algorithms may not be suitable for finding the shortest path between all pairs of nodes in a graph.

--------

## GPT3.5 Attempt \#1

It looks like you've already made some good progress in optimizing your code by switching from strings to lists. Here are a few more suggestions:

1. Use a `Dictionary` instead of a 2D array for your `connections` variable. This will allow you to store the connections for each pair of nodes using a key-value pair, where the key is a tuple of the two node indices and the value is a list of points representing the path between them. This will save memory compared to using a 2D array, especially if your graph is sparse (i.e. there are many pairs of nodes that are not connected).

Here's an example of how you could initialize the dictionary:

```
Dictionary<(int, int), List<Point>> connections = new Dictionary<(int, int), List<Point>>();
for (i = 0; i < V; i++){
  for (j = 0; j < V; j++){
    dist[i, j] = graph[i, j];
    connections[(i, j)] = new List<Point>() { new Point(i, j) };
  }
}
```

And here's how you could update the connections when you find a shorter path:

```
if (dist[i, k] + dist[k, j] < dist[i, j])
{
  dist[i, j] = dist[i, k] + dist[k, j];
  connections[(i, j)] = new List<Point>();
  connections[(i, j)].AddRange(connections[(i, k)]);
  connections[(i, j)].AddRange(connections[(k, j)]);
}
```

2. Use a `SparseMatrix` class instead of a 2D array for your `dist` variable. This will save memory if your graph is sparse, since it only stores the non-zero elements of the matrix. There are several libraries available for C# that provide sparse matrix classes, such as MathNet.Numerics and Extreme Optimization.

Here's an example of how you could initialize a sparse matrix using MathNet.Numerics:

```
using MathNet.Numerics.LinearAlgebra.Double;

SparseMatrix dist = new SparseMatrix(V, V);
for (i = 0; i < V; i++){
  for (j = 0; j < V; j++){
    dist[i, j] = graph[i, j];
  }
}
```

And here's how you could update the matrix when you find a shorter path:

```
if (dist[i, k] + dist[k, j] < dist[i, j])
{
  dist[i, j] = dist[i, k] + dist[k, j];
}
```

3. Consider using a different algorithm that is more memory-efficient for your specific problem. The Floyd-Warshall algorithm has a space complexity of O(V^2), which can be prohibitively large for very large graphs. There are other algorithms that can find the shortest path between all pairs of nodes in a graph with lower space complexity, such as Johnson's algorithm and the A* algorithm. However, these algorithms may have other trade-offs, such as slower runtime or more complex implementation.

--------

## GPT3.5 Attempt \#2

It's great that you were able to improve the performance by using `List`s instead of strings. Here are a few more suggestions to further optimize your code:

1. Use a `struct` instead of a `class` for `Point`
Since `Point` is a small data structure that only contains two integers, it might be more efficient to use a `struct` instead of a `class`. This is because a `struct` is a value type, which means that it is stored on the stack instead of the heap. This can reduce the overhead of memory allocation and garbage collection.

2. Use a jagged array instead of a `List` of `List`s
Instead of using a `List` of `List`s to store the paths, you could use a jagged array. A jagged array is an array of arrays, where each sub-array can have a different length. This can be more memory-efficient than a `List` of `List`s, because it avoids the overhead of the `List` class.

Here's an example of how you could use a jagged array to store the paths:

```
Point[][] paths = new Point[dictionary_size][];
for (int i = 0; i < dictionary_size; i++)
{
    paths[i] = new Point[dictionary_size];
    for (int j = 0; j < dictionary_size; j++)
    {
        paths[i][j] = new Point(i, j);
    }
}
```

This creates a jagged array of `Point`s with the same dimensions as the `dist` array. Each element of the `paths` array is initialized with a new `Point` object that represents the path from `i` to `j`.

To update the path when a shorter path is found, you can simply assign the `paths[i][j]` element to a new array that combines the paths from `i` to `k` and from `k` to `j`:

```
paths[i][j] = paths[i][k].Concat(paths[k][j].Skip(1)).ToArray();
```

This creates a new array that starts with the path from `i` to `k`, followed by the path from `k` to `j`, excluding the first element (which is the common vertex `k`).

3. Use a `Dictionary` instead of a `List` of `Point`s to store the paths
Another option is to use a `Dictionary` to store the paths. This can be more memory-efficient than a jagged array, because it only stores the paths that have been updated (i.e. the shortest paths). The keys of the `Dictionary` are tuples of `(int, int)` that represent the source and destination vertices, and the values are arrays of `Point`s that represent the shortest path.

Here's an example of how you could use a `Dictionary` to store the paths:

```
Dictionary<(int, int), Point[]> paths = new Dictionary<(int, int), Point[]>();
for (int i = 0; i < dictionary_size; i++)
{
    for (int j = 0; j < dictionary_size; j++)
    {
        paths[(i, j)] = new[] { new Point(i, j) };
    }
}
```

This creates a `Dictionary` with the same keys as the `paths` jagged array, and initializes each value with a new array that contains a single `Point` object representing the direct path from `i` to `j`.

To update the path when a shorter path is found, you can simply replace the value of the `(i, j)` key with a new array that combines the paths from `i` to `k` and from `k` to `j`:

```
paths[(i, j)] = paths[(i, k)].Concat(paths[(k, j)].Skip(1)).ToArray();
```

This creates a new array that starts with the path from `i` to `k`, followed by the path from `k` to `j`, excluding the first element (which is the common vertex `k`).

I hope these suggestions help you further optimize your code!

--------
