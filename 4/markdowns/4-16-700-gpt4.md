
# Post \#70896179 [Link](https://stackoverflow.com/questions/70896179/)

## How to filter text data in bash more efficiently

**Vote**: 1 (672/702) **Views**: 878 (668/702) 

**Internal ID** \#4-16-700

Created at 2022-01-28 15:27:31

Tags: `bash`

----------

#### Metadata:

Area: `IT Operations`

Language: `bash` (full parsed tag list: `bash`)

----------

**Notepad**


----------

I have data file which I need to filter with bash script, see data example:
```
name=pencils
name=apples
value=10
name=rocks
value=3
name=tables
value=6
name=beds
name=cups
value=89
```

I need to group  pairs like so , if current line starts with name and next line starts with name, first line should be omitted entirely. So result file should look like this:
```
apples=10
rocks=3
tables=6
cups=89
```

I came with this simple solution which works but is very slow, it takes 5 min to complete for file with 2000 lines.
```
VALUES=$(cat input.txt)
for x in $VALUES; do
  if [[ -n $(echo $x | grep 'name=') ]]; then
    name=$(echo $x | sed "s/name=//")
  elif [[ -n $(echo $x | grep 'value=') ]]; then
    value=$(echo $x | sed "s/value=//")
    echo "${name}=${value}" >> output.txt
  fi
done
```

I'm aware that this kind of task is not very suitable for bash, but script is already written and this is just small part of it.
How can I optimize this task in bash?


----------
        
## GPT4 Attempt \#0

The script you provided is slow because it performs a lot of unnecessary operations. For each line, it invokes `grep` and `sed` twice, and it also writes to the output file. All these operations are quite expensive in terms of performance.

Here's a more efficient way to do it using awk:

```bash
awk -F'=' '/^name/{name=$2;next} /^value/{print name"="$2}' input.txt > output.txt
```

This script works as follows:

- `-F'='` sets the field separator to `=`.
- `/^name/` matches lines that start with `name`. For these lines, it saves the second field (the part after the `=`) in the variable `name` and then skips to the next line.
- `/^value/` matches lines that start with `value`. For these lines, it prints the previously saved name and the current value.

This script only reads the input file once and writes to the output file once, so it should be much faster than your original script. It also doesn't use any external commands, which further improves performance.

--------

## GPT4 Attempt \#1

You can optimize your bash script by using awk, which is a powerful text processing tool. Here's how you can do it:

```bash
awk -F'=' '
    /^name/ {name=$2; next} 
    /^value/ && name {print name"="$2; name=""}
' input.txt > output.txt
```

This script works as follows:

- `-F'='` sets the field separator to `=`.
- `/^name/ {name=$2; next}`: If the line starts with `name`, it saves the value (the part after `=`) in the `name` variable and skips to the next line.
- `/^value/ && name {print name"="$2; name=""}`: If the line starts with `value` and `name` is not empty, it prints `name=value` and then clears the `name` variable.

This script should be significantly faster than your original script because it processes the file line by line and doesn't use any external commands like `grep` or `sed`. It also writes the output to `output.txt` in a single operation, which is more efficient than appending to the file in a loop.

--------

## GPT4 Attempt \#2

You can optimize your script by using `awk` command. `awk` is a powerful tool for processing or analyzing text files, especially useful when you need to process data based on columns or rows. 

Here is a script that should do the job:

```bash
awk -F'=' '
  /^name/ {name=$2; next} 
  /^value/ {print name"="$2}
' input.txt > output.txt
```

This script works as follows:

- `-F'='` sets the field separator to `=`.
- `/^name/ {name=$2; next}` if the line starts with `name`, it saves the value (the second field) to the variable `name` and skips to the next line.
- `/^value/ {print name"="$2}` if the line starts with `value`, it prints the previously saved name and the value (the second field).

This script should be significantly faster than your original script because it processes the file line by line and doesn't use any external commands or regular expressions. It also writes the output directly to the output file, so it doesn't need to keep all the data in memory.

--------
