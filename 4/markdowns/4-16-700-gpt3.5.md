
# Post \#70896179 [Link](https://stackoverflow.com/questions/70896179/)

## How to filter text data in bash more efficiently

**Vote**: 1 (672/702) **Views**: 878 (668/702) 

**Internal ID** \#4-16-700

Created at 2022-01-28 15:27:31

Tags: `bash`

----------

#### Metadata:

Area: `IT Operations`

Language: `bash` (full parsed tag list: `bash`)

----------

**Notepad**


----------

I have data file which I need to filter with bash script, see data example:
```
name=pencils
name=apples
value=10
name=rocks
value=3
name=tables
value=6
name=beds
name=cups
value=89
```

I need to group  pairs like so , if current line starts with name and next line starts with name, first line should be omitted entirely. So result file should look like this:
```
apples=10
rocks=3
tables=6
cups=89
```

I came with this simple solution which works but is very slow, it takes 5 min to complete for file with 2000 lines.
```
VALUES=$(cat input.txt)
for x in $VALUES; do
  if [[ -n $(echo $x | grep 'name=') ]]; then
    name=$(echo $x | sed "s/name=//")
  elif [[ -n $(echo $x | grep 'value=') ]]; then
    value=$(echo $x | sed "s/value=//")
    echo "${name}=${value}" >> output.txt
  fi
done
```

I'm aware that this kind of task is not very suitable for bash, but script is already written and this is just small part of it.
How can I optimize this task in bash?


----------
        
## GPT3.5 Attempt \#0

One way to optimize this task in bash is to use awk instead of a for loop. Awk is a powerful tool for text processing and can handle this task much faster than a bash loop.

Here's an example awk command that should do what you need:

```
awk '/name=/ {name=$2} /value=/ {if (name) print name "=" $2; name=""}' input.txt > output.txt
```

This command uses two regular expressions to match lines that start with "name=" and "value=". When a line starting with "name=" is found, it saves the name in a variable. When a line starting with "value=" is found, it prints the name and value as a pair, and resets the name variable.

This command should be much faster than your original bash script, even for large files.

--------

## GPT3.5 Attempt \#1

One way to optimize this task is to use awk instead of bash. Awk is a powerful tool for text processing and can handle this task much faster than bash.

Here's an example awk script that should do what you need:

```
awk '/name=/ {name=$2} /value=/ {if (name) print name "=" $2; name=""}' input.txt > output.txt
```

This script uses two regular expressions to match lines that start with "name=" and "value=". When it finds a line that starts with "name=", it saves the name in a variable. When it finds a line that starts with "value=", it prints the name and value as a pair, and then resets the name variable.

This script should be much faster than your bash script, even for large input files.

--------

## GPT3.5 Attempt \#2

One way to optimize this task is to use awk instead of a bash loop. Awk is a powerful text processing tool that can handle this kind of task efficiently. Here's an example awk script that should do what you need:

```
awk -F= '
  /^name=/ { name=$2 }
  /^value=/ && name { print name "=" $2; name="" }
' input.txt > output.txt
```

This script sets the field separator to "=" using the `-F` option, then uses two patterns to match lines starting with "name=" and "value=". When it sees a line starting with "name=", it saves the name in a variable. When it sees a line starting with "value=" and there is a saved name, it prints the name and value separated by "=".

This should be much faster than the bash loop, especially for larger files.

--------
