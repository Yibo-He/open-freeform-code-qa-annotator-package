
# Post \#65750773 [Link](https://stackoverflow.com/questions/65750773/)

## Take desktop screenshot with Electron

**Vote**: 4 (532/702) **Views**: 9997 (416/702) 

**Internal ID** \#0-0-101

Created at 2021-01-16 14:29:46

Tags: `javascript` `angular` `electron`

----------

#### Metadata:

Area: `Front-end`

Language: `javascript` (full parsed tag list: `javascript`)

----------

**Notepad**


----------

I am using Electron to create a Windows application that creates a fullscreen transparent overlay window. The purpose of this overlay is to:

1. take a screenshot of the entire screen (not the overlay itself which is transparent, but the screen 'underneath'),
2. process this image by sending the image as a byte stream to my python server, and
3. draw some things on the overlay


I am getting stuck on the first step, which is the screenshot capturing process.
I tried , which is to use `capturePage()`:
```
this.electronService.remote.getCurrentWindow().webContents.capturePage()
    .then((img: Electron.NativeImage) => { ... }
```

but this captures my overlay window only (and not the desktop screen). This will be a blank image which is useless to me.
 is to use `desktopCapturer`:
```
this.electronService.remote.desktopCapturer.getSources({types: ['screen']}).then(sources => {
    for (const source of sources) {
        if (source.name === 'Screen 1') {
            try {
                const mediaDevices = navigator.mediaDevices as any;
                mediaDevices.getUserMedia({
                    audio: false,
                    video: { // this specification is only available for Chrome -> Electron runs on Chromium browser
                        mandatory: {
                            chromeMediaSource: 'desktop',
                            chromeMediaSourceId: source.id,
                            minWidth: 1280,
                            maxWidth: 1280,
                            minHeight: 720,
                            maxHeight: 720
                        }
                    }
                }).then((stream: MediaStream) => { // stream.getVideoTracks()[0] contains the video track I need
                    this.handleStream(stream);
                });
            } catch (e) {
            }
        }
    }
});
```

The next step is where it becomes fuzzy for me.  What do I do with the acquired `MediaStream` to get a bytestream from the screenshot out of it? I see plenty of examples how to display this stream on a webpage, but I wish to send it to my backend. [This StackOverflow post](https://stackoverflow.com/questions/51543595/get-a-stream-of-bytes-from-navigator-mediadevices-getusermedia) mentions how to do it, but I am not getting it to work properly.  This is how I implemented `handleStream()`:
```
import * as MediaStreamRecorder from 'msr';

private handleStream(stream: MediaStream): void {
    recorder.stop()
    const recorder = new MediaStreamRecorder(stream);
    recorder.ondataavailable = (blob: Blob) => { // I immediately get a blob, while the linked SO page got an event and had to get a blob through event.data
        this.http.post<Result>('http://localhost:5050', blob);
    };

    // make data available event fire every one second
    recorder.start(1000);
}
```

The `blob` is not being accepted by the Python server.  Upon inspecting the contents of `Blob`, it's a video as I suspected.  I verified this with the following code:
```
let url = URL.createObjectURL(blob);
window.open(url, '_blank')
```

which opens the blob in a new window. It displays a video of maybe half a second, but I want to have a static image. So how do I get a specific snapshot out of it? I'm also not sure if simply sending the Javascript blob format in the POST body will do for Python to be correctly interpret it. In Java it works by simply sending a `byte[]` of the image so I verified that the Python server implementation works as expected.
Any suggestions other than using the `desktopCapturer` are also fine.  This implementation is capturing my mouse as well, which I rather not have.  I must admit that I did not expect this feature to be so difficult to implement.


----------
        
## GPT4 Attempt \#0

The `desktopCapturer` API in Electron is indeed designed to capture video of the desktop, not static images. However, you can use it to capture a single frame of video and use that as a screenshot.

Here's a rough idea of how you might do this:

1. Use `desktopCapturer.getSources()` to get a `MediaStream` of the desktop video.
2. Create a `Video` element and set its `srcObject` to the `MediaStream`.
3. Wait for the video to load a frame, then draw that frame to a `Canvas` element.
4. Use `Canvas.toBlob()` to get a `Blob` of the image data.

Here's some sample code to illustrate these steps:

```javascript
const video = document.createElement('video');
video.onloadedmetadata = () => {
  video.play();

  // Wait for video to play, then draw a frame to the canvas
  video.onplaying = () => {
    const canvas = document.createElement('canvas');
    canvas.width = video.videoWidth;
    canvas.height = video.videoHeight;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    // Get a Blob of the image data
    canvas.toBlob(blob => {
      // Now you can send the blob to your server
      this.http.post<Result>('http://localhost:5050', blob);
    });
  };
};

navigator.mediaDevices.getUserMedia({
  audio: false,
  video: {
    mandatory: {
      chromeMediaSource: 'desktop',
      chromeMediaSourceId: source.id,
      minWidth: 1280,
      maxWidth: 1280,
      minHeight: 720,
      maxHeight: 720
    }
  }
}).then(stream => {
  video.srcObject = stream;
});
```

This code will capture a single frame of video as soon as the video starts playing. If you want to capture a frame at a later time, you can move the code inside `video.onplaying` to a separate function and call it when needed.

As for sending the `Blob` to your Python server, you'll need to convert it to a format that your server can understand. The `Blob` object represents a chunk of binary data, so you'll need to read it as such on the server side. In Python, you can use the `io.BytesIO` class to read the incoming data as a byte stream.

--------

## GPT4 Attempt \#1

The `desktopCapturer` in Electron indeed captures video, not static images. However, you can use the captured video stream to create a snapshot. Here's how you can do it:

1. Create a hidden `video` element and set the stream as its source.
2. Create a `canvas` element, draw the current frame of the video onto the canvas, and then use `canvas.toDataURL()` to get an image.

Here's an example of how you can modify your `handleStream` function to do this:

```javascript
private handleStream(stream: MediaStream): void {
    // Create a hidden video element
    const video = document.createElement('video');
    video.style.display = 'none';
    document.body.appendChild(video);

    // Set the stream as the video source
    video.srcObject = stream;
    video.play();

    // Wait for the video to start playing
    video.onplaying = () => {
        // Create a canvas and draw the current frame of the video onto it
        const canvas = document.createElement('canvas');
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;
        const context = canvas.getContext('2d');
        context.drawImage(video, 0, 0, canvas.width, canvas.height);

        // Get the image data from the canvas
        const imageData = canvas.toDataURL();

        // Send the image data to the server
        this.http.post<Result>('http://localhost:5050', imageData);

        // Clean up
        document.body.removeChild(video);
    };
}
```

This will send the image data as a base64-encoded string. On your Python server, you can decode this string to get the image data. Here's an example of how you can do this in Python:

```python
import base64
from flask import Flask, request

app = Flask(__name__)

@app.route('/', methods=['POST'])
def handle_post():
    # Get the image data from the request
    image_data = request.get_data()

    # Decode the base64 string
    image_data = base64.b64decode(image_data.split(',')[1])

    # Save the image
    with open('image.png', 'wb') as f:
        f.write(image_data)

    return 'OK'
```

This will save the image as a PNG file. You can change the filename and the file format as needed.

Please note that this code assumes that the image data is sent as a base64-encoded PNG image. If you're using a different image format, you'll need to adjust the code accordingly.

--------

## GPT4 Attempt \#2

The `desktopCapturer` API in Electron indeed captures video streams, which is not exactly what you need. You need a single frame (image) from that stream. 

Here's a way to do it:

1. Capture the stream as you're doing now.
2. Create a hidden `video` element in your HTML and set the stream as its source.
3. Create a `canvas` element, draw the current frame of the video onto the canvas, and then export the canvas to a data URL or a Blob.
4. Send this data to your server.

Here's a rough example of how you might implement this:

```javascript
private handleStream(stream: MediaStream): void {
    // Create hidden video element
    let video = document.createElement('video');
    video.style.display = 'none';
    document.body.appendChild(video);

    // Create hidden canvas element
    let canvas = document.createElement('canvas');
    canvas.style.display = 'none';
    document.body.appendChild(canvas);

    // Set stream as video source
    video.srcObject = stream;
    video.play();

    // When video data is loaded
    video.onloadeddata = () => {
        // Set canvas dimensions same as video dimensions
        canvas.width = video.videoWidth;
        canvas.height = video.videoHeight;

        // Draw video frame to canvas
        canvas.getContext('2d').drawImage(video, 0, 0, canvas.width, canvas.height);

        // Export canvas to data URL (base64 encoded string)
        let screenshot = canvas.toDataURL();

        // Or export canvas to Blob
        canvas.toBlob((blob) => {
            // Send Blob to server
            this.http.post<Result>('http://localhost:5050', blob);
        });

        // Remove video and canvas elements
        document.body.removeChild(video);
        document.body.removeChild(canvas);
    };
}
```

This will give you a single frame from the video stream, which you can then send to your server. The frame will be taken as soon as the video data is loaded, so it should be almost instant.

As for the mouse cursor being captured, this is a limitation of the `desktopCapturer` API and there's no way to avoid it as far as I know. You might need to use a different method to capture the screen if you don't want the cursor to be included.

--------
