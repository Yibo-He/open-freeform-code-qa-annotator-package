To solve the problem of multiple workers having their own `meta` objects, you can use a shared memory solution such as Redis or Memcached. These tools allow you to store data in a shared memory space that can be accessed by multiple processes or workers.

Here's an example of how you can use Redis to share the `meta` object between workers:

1. Install the Redis library for Python:

```
pip install redis
```

2. Create a Redis client and use it to store the `meta` object:

```
import redis

redis_client = redis.Redis(host='localhost', port=6379, db=0)
redis_client.set('meta', pickle.dumps(Meta()))
```

3. In your endpoints, retrieve the `meta` object from Redis, modify it, and store it back:

```
@app.get("/increment")
async def increment():
    meta = pickle.loads(redis_client.get('meta'))
    meta.count += 1
    redis_client.set('meta', pickle.dumps(meta))
    return status.HTTP_200_OK

@app.get("/report")
async def report():
    meta = pickle.loads(redis_client.get('meta'))
    return {'count': meta.count}

@app.get("/reset")
async def reset():
    meta = pickle.loads(redis_client.get('meta'))
    meta.count = 0
    redis_client.set('meta', pickle.dumps(meta))
    return status.HTTP_200_OK
```

This way, all workers will be able to access and modify the same `meta` object stored in Redis.

As for your side question, there's no built-in way to force all workers to respond to a single call on an endpoint. However, you can use a similar approach as above to store a flag in Redis that indicates whether a reset has been requested, and have each worker check this flag periodically. If the flag is set, the worker can reset its own `meta` object.