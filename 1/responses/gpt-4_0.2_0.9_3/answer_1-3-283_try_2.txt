Yes, you can use multiprocessing to speed up the process. Here's how you can modify your function to use Python's multiprocessing module:

```python
import multiprocessing as mp
import numpy as np

def worker(args):
    i, n = args
    row = [1/(i+j-1) for j in range(1, n+1)]
    return row

def createMatrix(n):
    pool = mp.Pool(mp.cpu_count())
    matrix = pool.map(worker, [(i, n) for i in range(1, n+1)])
    pool.close()
    return np.array(matrix)
```

In this version of the function, the `worker` function is what each process will run. It takes a tuple of arguments, which includes the row index and the size of the matrix. The `createMatrix` function creates a pool of processes, then uses the `map` function to apply the `worker` function to each row index. The results are collected into a list, which is then converted to a numpy array.

This should speed up the creation of the matrix, as the work is being done in parallel. However, keep in mind that there is overhead associated with creating processes and communicating between them, so this might not be faster for small matrices. Also, the speedup will be limited by the number of cores on your machine.

Also, note that this will only work if the calculation of each row is independent of the others. If they are not, you will need to use a different approach.