The process you're using is already quite optimized for the task you're trying to accomplish. However, there are a few things you can try to speed up the process:

1. **Use fewer bins**: The number of groups is proportional to the cube of the number of bins (since you're grouping by three variables). Reducing the number of bins will reduce the number of groups and should speed up the process.

2. **Use `transform` instead of `agg`**: The `transform` method can be faster than `agg` in some cases. However, it returns a DataFrame that has the same length as the input, so you'll need to drop duplicates afterwards.

3. **Use a smaller data type**: If your data allows it, using a smaller data type can speed up the process. For example, if your values are integers, you can use the `int` data type instead of `float`.

4. **Use a different library**: Pandas is not always the fastest library for every task. If speed is a critical factor, you might want to try using a library like Dask, which is designed for parallel computing and can be faster than Pandas for some tasks.

Here's an example of how you might implement these suggestions:

```python
df['value'] = df['value'].astype('float32')  # use a smaller data type

# use fewer bins
bins = np.arange(-3, 4, 0.1)

df['a_bins'] = pd.cut(df['a'], bins=bins)
df['b_bins'] = pd.cut(df['b'], bins=bins)
df['c_bins'] = pd.cut(df['c'], bins=bins)

# use transform instead of agg
df['mean'] = df.groupby(['a_bins','b_bins','c_bins'])['value'].transform('mean')
df = df.drop_duplicates(['a_bins','b_bins','c_bins'])
```

To find the mean value for specific a, b, and c values, you can use the `query` method:

```python
df.query('a_bins == -1.72 and b_bins == 0.32 and c_bins == 1.18')['mean']
```

Please note that these suggestions might not always result in a speedup, depending on the specifics of your data and your computing environment. It's always a good idea to test different approaches and see what works best for your specific situation.