Yes, you can definitely speed up your code by using multiprocessing. Python's multiprocessing module allows you to create multiple processes, each with its own Python interpreter, which can overcome the Global Interpreter Lock (GIL) and make full use of multiple processors on a machine.

Here's how you can modify your code to use multiprocessing:

```python
import numpy as np
from multiprocessing import Pool

def calculate_value(params):
    i, j = params
    return 1/(i+j-1)

def createMatrix(n):
    with Pool() as p:
        matrix = []
        for j in range(1,n+1):
            row_params = [(i, j) for i in range(1, n+1)]
            row = p.map(calculate_value, row_params)
            matrix.append(row)
    return np.array(matrix)
```

In this code, we use a Pool of worker processes. We map the `calculate_value` function over the parameters for each row. The `map` function automatically distributes the computations over the available processors.

However, please note that multiprocessing introduces some overhead, because data needs to be pickled and unpickled to be sent between the main process and the worker processes. Therefore, it is most effective when the amount of computation done in each function call is large compared to the amount of data that needs to be transferred.

In your case, the computation done in each function call is quite small (just a single division), so the overhead of multiprocessing might actually make the code slower. You might want to consider other ways of speeding up your code, such as using NumPy's vectorized operations. Here's how you can do it:

```python
def createMatrix(n):
    i = np.arange(1, n+1)
    j = np.arange(1, n+1).reshape(-1, 1)
    matrix = 1 / (i + j - 1)
    return matrix
```

This code creates two arrays `i` and `j`, and then uses broadcasting to perform the division on all pairs of `i` and `j` at once. This is likely to be much faster than either the original code or the multiprocessing version, because NumPy's vectorized operations are implemented in C and can take advantage of low-level optimizations.