
# Post \#70240506 [Link](https://stackoverflow.com/questions/70240506/)

## Why is numpy native on M1 Max greatly slower than on old Intel i5?

**Vote**: 14 (336/702) **Views**: 10662 (410/702) 

**Internal ID** \#1-3-203

Created at 2021-12-06 03:16:05

Tags: `python` `numpy` `tensorflow` `anaconda` `apple-m1`

----------

#### Metadata:

Area: `Data Science & Machine Learning`

Language: `python` (full parsed tag list: `python`)

----------

**Notepad**


----------

I just got my new MacBook Pro with M1 Max chip and am setting up Python. I've tried several combinational settings to test speed - now I'm quite confused. First put my questions here:
- - - - 
Evidence supporting my questions is as follows:

---


Here are the settings I've tried:

- [Miniforge-arm64](https://github.com/conda-forge/miniforge)`Kind``Apple`- [Anaconda](https://docs.anaconda.com/anaconda/install/mac-os/)`Kind``Intel`

- `conda install numpy`- 
```
conda install -c apple tensorflow-deps
python -m pip install tensorflow-macos
python -m pip install tensorflow-metal
```


- - [Apple Silicon version](https://www.jetbrains.com/pycharm/download/download-thanks.html?platform=macM1)

---


Here is the test code:
```
import time
import numpy as np
np.random.seed(42)
a = np.random.uniform(size=(300, 300))
runtimes = 10

timecosts = []
for _ in range(runtimes):
    s_time = time.time()
    for i in range(100):
        a += 1
        np.linalg.svd(a)
    timecosts.append(time.time() - s_time)

print(f'mean of {runtimes} runs: {np.mean(timecosts):.5f}s')
```

and here are the results:
```
+-----------------------------------+-----------------------+--------------------+
|   Python installed by (run on)→   | Miniforge (native M1) | Anaconda (Rosseta) |
+----------------------+------------+------------+----------+----------+---------+
| Numpy installed by ↓ | Run from → |  Terminal  |  PyCharm | Terminal | PyCharm |
+----------------------+------------+------------+----------+----------+---------+
|          Apple Tensorflow         |   4.19151  |  4.86248 |     /    |    /    |
+-----------------------------------+------------+----------+----------+---------+
|        conda install numpy        |   4.29386  |  4.98370 |  4.10029 | 4.99271 |
+-----------------------------------+------------+----------+----------+---------+
```

This is quite slow. For comparison,
- `2.39917s`- [post (but not in English)](https://www.zhihu.com/question/431073191/answer/1657202944)`2.53214s``1.00613s`- 
Here is the CPU information details:
- 
```
$ sysctl -a | grep -e brand_string -e cpu.core_count
machdep.cpu.brand_string: Intel(R) Core(TM) i5-6360U CPU @ 2.00GHz
machdep.cpu.core_count: 2
```

- 
```
% sysctl -a | grep -e brand_string -e cpu.core_count
machdep.cpu.brand_string: Apple M1 Max
machdep.cpu.core_count: 10
```


---


I follow instructions strictly from tutorials - but why would all these happen? Is it because of my installation flaws, or because of M1 Max chip? Since my work relies heavily on local runs, local speed is very important to me. Any suggestions to possible solution, or any data points on your own device would be greatly appreciated :)


----------
        
## GPT3.5 Attempt \#0

It's possible that the slow performance is due to compatibility issues with the M1 Max chip. Some software may not be optimized for this new architecture yet. However, there are a few things you can try to improve performance:

1. Use native M1 versions of software whenever possible. This means using software that has been specifically compiled for the M1 chip. For example, you can try using the Miniforge-arm64 installation instead of Anaconda.

2. Use Apple's Metal API for GPU acceleration. This can significantly improve performance for certain tasks. You can try installing the Metal version of TensorFlow and see if that helps.

3. Use a different IDE or editor. PyCharm may not be optimized for the M1 chip yet. You can try using a different IDE or editor, such as VS Code or Sublime Text, and see if that improves performance.

4. Check your code for any inefficiencies. It's possible that your code could be optimized to run faster. You can try profiling your code to identify any bottlenecks and optimize accordingly.

5. Wait for updates. As more software is updated to support the M1 chip, performance should improve. Keep an eye out for updates to the software you're using and install them as they become available.

It's also worth noting that the performance of your M1 Max chip is still very good compared to the Intel Core i5-6360U CPU in your previous machine. Even though the benchmarks you're seeing may be slower than expected, your new machine is still likely much faster overall.

--------

## GPT3.5 Attempt \#1

It's possible that the slow performance you're experiencing is due to compatibility issues with the M1 Max chip. While many software packages have been updated to support the new chip architecture, there may still be some that are not fully optimized yet. 

One thing you could try is using the `pip` package manager instead of `conda` to install your Python packages. `pip` is generally more lightweight and may be better suited for the M1 Max chip. You could also try using the `--use-feature=2020-resolver` flag when installing packages with `pip`, as this can sometimes help resolve compatibility issues.

Another thing to consider is using a virtual environment to isolate your Python installation and packages. This can help ensure that you're using the correct versions of packages and avoid conflicts between different versions of Python.

Finally, it's worth noting that performance can vary depending on the specific task you're trying to perform. While your test code is a good benchmark, it may not be representative of the performance you'll see in your actual work. It's always a good idea to test your code on your specific hardware and see how it performs before making any decisions about optimization.

--------

## GPT3.5 Attempt \#2

It's possible that the slow performance is due to compatibility issues with the M1 Max chip. Some libraries may not have been optimized for this architecture yet. 

Here are some suggestions that may help improve performance:

1. Use the latest version of Python that is optimized for the M1 chip. You can download it from the official Python website.

2. Use the latest version of NumPy that is optimized for the M1 chip. You can install it using `pip install numpy`.

3. Use TensorFlow with Metal support. This can be installed using `pip install tensorflow-metal`.

4. Use PyTorch with Metal support. This can be installed using `pip install torch-macos`.

5. Use a code editor that is optimized for the M1 chip, such as Visual Studio Code or PyCharm.

6. Use the latest version of macOS and keep your system updated.

7. If possible, try running your code on a cloud-based service that provides M1 Max instances, such as AWS or Google Cloud.

I hope these suggestions help improve your performance.

--------
