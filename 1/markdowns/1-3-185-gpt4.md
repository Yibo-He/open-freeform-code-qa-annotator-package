
# Post \#60145306 [Link](https://stackoverflow.com/questions/60145306/)

## Remove background text and noise from an image using image processing with OpenCV

**Vote**: 11 (370/702) **Views**: 17358 (329/702) 

**Internal ID** \#1-3-185

Created at 2020-02-10 06:45:51

Tags: `python` `image` `opencv` `image-processing` `computer-vision`

----------

#### Metadata:

Area: `Data Science & Machine Learning`

Language: `python` (full parsed tag list: `python`)

----------

**Notepad**


----------

I have these images

[](https://i.stack.imgur.com/VOfgD.png)

[](https://i.stack.imgur.com/TdRKg.png)

For which I want to remove the text in the background. Only the `captcha characters` should remain(i.e K6PwKA, YabVzu). The task is to identify these characters later using tesseract.

This is what I have tried, but it isn't giving much good accuracy.

```
import cv2
import pytesseract

pytesseract.pytesseract.tesseract_cmd = r"C:\Users\HPO2KOR\AppData\Local\Tesseract-OCR\tesseract.exe"
img = cv2.imread("untitled.png")
gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
gray_filtered = cv2.inRange(gray_image, 0, 75)
cv2.imwrite("cleaned.png", gray_filtered)
```


How can I improve the same?

 
I tried all the suggestion that I was getting for this question and none of them worked for me.

 
According to Elias, I tried finding the color of the captcha text using photoshop by converting it to grayscale which came out to be somewhere in between [100, 105]. I then threshold the image based on this range. But the result which I got did not give satisfactory result from tesseract.

```
gray_filtered = cv2.inRange(gray_image, 100, 105)
cv2.imwrite("cleaned.png", gray_filtered)
gray_inv = ~gray_filtered
cv2.imwrite("cleaned.png", gray_inv)
data = pytesseract.image_to_string(gray_inv, lang='eng')
```


Output :

```
'KEP wKA'
```


Result : 

[](https://i.stack.imgur.com/AqYeO.png)



```
def get_text(img_name):
    lower = (100, 100, 100)
    upper = (104, 104, 104) 
    img = cv2.imread(img_name)
    img_rgb_inrange = cv2.inRange(img, lower, upper)
    neg_rgb_image = ~img_rgb_inrange
    cv2.imwrite('neg_img_rgb_inrange.png', neg_rgb_image)
    data = pytesseract.image_to_string(neg_rgb_image, lang='eng')
    return data
```


gives : 

[](https://i.stack.imgur.com/rSrSz.png)

and the text as

```
GXuMuUZ
```


Is there any way to soften it a little


----------
        
## GPT4 Attempt \#0

The problem you're facing is a common one in the field of Optical Character Recognition (OCR). The background noise in the images is interfering with the OCR's ability to accurately recognize the characters. 

Here are some steps you can take to improve the accuracy:

1. **Image Binarization**: This is a process of converting an image to black and white. This can help to remove some of the noise in the image. You can use Otsu's Binarization method which automatically calculates a threshold value from image histogram for a bimodal image. 

2. **Morphological Operations**: You can apply morphological operations like dilation and erosion to remove small noise - the operations like Dilation expands the object area and Erosion shrinks it. 

3. **Smoothing**: You can apply a Gaussian blur to the image to reduce high frequency noise, helping in the extraction of meaningful data. 

4. **Rescaling**: Tesseract works best on images that are 300 dpi or higher, so you might get better results if you rescale your images before processing them.

Here's an example of how you might implement these steps:

```python
import cv2
import pytesseract

def preprocess_for_ocr(img, enhance=1):
    """
    @param img: image to which the pre-processing steps being applied
    """
    if enhance > 1:
        img = cv2.resize(img, None, fx=enhance, fy=enhance, interpolation=cv2.INTER_LINEAR)
    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
    img = cv2.medianBlur(img, 3)
    return img

pytesseract.pytesseract.tesseract_cmd = r"C:\Users\HPO2KOR\AppData\Local\Tesseract-OCR\tesseract.exe"
img = cv2.imread("untitled.png")
processed_img = preprocess_for_ocr(img, enhance=2)
cv2.imwrite("cleaned.png", processed_img)
```

Remember that OCR is not always 100% accurate, and the accuracy can depend on the quality of the original image. You might need to experiment with different pre-processing steps to find the best results for your specific images.

--------

## GPT4 Attempt \#1

The task you're trying to accomplish is a bit challenging due to the noise in the background. However, you can try a few image processing techniques to improve the results. Here are some steps you can follow:

1. Convert the image to grayscale.
2. Apply a Gaussian blur to the image to reduce noise.
3. Use adaptive thresholding to convert the image to binary.
4. Apply morphological operations like dilation and erosion to remove small noise.

Here is a Python code snippet that implements these steps:

```python
import cv2
import pytesseract

def get_text(img_name):
    # Load the image
    img = cv2.imread(img_name)

    # Convert the image to gray scale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Apply Gaussian blur to the image
    blurred = cv2.GaussianBlur(gray, (5, 5), 0)

    # Use adaptive thresholding to convert the image to binary
    thresh = cv2.adaptiveThreshold(blurred, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)

    # Invert the image
    inverted = cv2.bitwise_not(thresh)

    # Apply morphological operations
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))
    dilated = cv2.dilate(inverted, kernel, iterations=1)
    eroded = cv2.erode(dilated, kernel, iterations=1)

    # Save the processed image
    cv2.imwrite('processed.png', eroded)

    # Use Tesseract to extract text
    text = pytesseract.image_to_string(eroded, lang='eng')

    return text

print(get_text('your_image.png'))
```

This code should give you better results. However, keep in mind that the parameters used in the functions like `GaussianBlur`, `adaptiveThreshold`, `dilate`, and `erode` might need to be adjusted based on your specific images. 

Also, Tesseract might not be able to perfectly recognize the text due to the complexity of the captcha. You might need to train Tesseract with similar captcha images for better accuracy.

--------

## GPT4 Attempt \#2

The task you are trying to accomplish is a bit tricky because the text you want to keep and the text you want to remove are quite similar in color and size. However, you can try to improve the results by applying some image processing techniques such as blurring, thresholding, and morphological operations.

Here's an example of how you might approach this:

```python
import cv2
import numpy as np
import pytesseract

def clean_image(img_path):
    # Load the image
    img = cv2.imread(img_path)

    # Convert the image to grayscale
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

    # Apply a slight Gaussian blur to the image
    blur = cv2.GaussianBlur(gray, (3, 3), 0)

    # Threshold the image to isolate the characters
    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)

    # Perform a series of erosions and dilations to remove any small blobs of noise
    kernel = np.ones((3, 3), np.uint8)
    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)

    # Find sure background area
    sure_bg = cv2.dilate(opening, kernel, iterations=3)

    # Finding sure foreground area
    dist_transform = cv2.distanceTransform(opening, cv2.DIST_L2, 5)
    _, sure_fg = cv2.threshold(dist_transform, 0.7 * dist_transform.max(), 255, 0)

    # Finding unknown region
    sure_fg = np.uint8(sure_fg)
    unknown = cv2.subtract(sure_bg, sure_fg)

    # Marker labelling
    _, markers = cv2.connectedComponents(sure_fg)

    # Add one to all labels so that sure background is not 0, but 1
    markers = markers + 1

    # Now, mark the region of unknown with zero
    markers[unknown == 255] = 0

    markers = cv2.watershed(img, markers)
    img[markers == -1] = [255, 0, 0]

    # Convert image to binary
    _, binary = cv2.threshold(img, 150, 255, cv2.THRESH_BINARY_INV)

    return binary

def get_text(img_path):
    img = clean_image(img_path)
    text = pytesseract.image_to_string(img)
    return text
```

This script first applies a Gaussian blur to the image to reduce noise. Then, it uses Otsu's binarization to threshold the image. After that, it performs a series of erosions and dilations to remove any small blobs of noise. Finally, it uses the watershed algorithm to separate overlapping objects.

Please note that the parameters used in this script might need to be adjusted depending on the specific characteristics of your images. Also, keep in mind that Tesseract might not be able to perfectly recognize the characters in the images due to the complexity and variability of the CAPTCHA.

--------
