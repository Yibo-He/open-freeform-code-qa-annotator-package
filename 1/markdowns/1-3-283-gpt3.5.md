
# Post \#72618859 [Link](https://stackoverflow.com/questions/72618859/)

## Run two nested for loops in parallel to create matrix

**Vote**: 2 (631/702) **Views**: 777 (678/702) 

**Internal ID** \#1-3-283

Created at 2022-06-14 14:36:17

Tags: `python` `multithreading` `numpy`

----------

#### Metadata:

Area: `Data Science & Machine Learning`

Language: `python` (full parsed tag list: `python`)

----------

**Notepad**


----------

I've written a method that takes in an integer "n" and creates a square matrix where the values of each element are dictated by their respective i,j indices.
When I build a small matrix 30x30 it works just fine, but when I try to do something larger like 1000x1000 it takes very long. Is there any way that I can speed it up with multiprocessing?
```
def createMatrix(n):
    matrix = []
    for j in range(1,n+1):
        row = []
        for i in range(1,n+1):
            value = 1/(i+j-1)
            row.append(value)
        matrix.append(row)
    return np.array(matrix)
```



----------
        
## GPT3.5 Attempt \#0

Yes, you can speed up the execution time of your function by using multiprocessing. One way to do this is to split the matrix creation into smaller chunks and process them in parallel using multiple processes. Here's an example implementation using the `multiprocessing` module:

```
import numpy as np
import multiprocessing as mp

def createMatrixChunk(start, end, n):
    chunk = []
    for j in range(start, end):
        row = []
        for i in range(1, n+1):
            value = 1/(i+j-1)
            row.append(value)
        chunk.append(row)
    return chunk

def createMatrix(n, num_processes=4):
    pool = mp.Pool(num_processes)
    chunk_size = n // num_processes
    results = []
    for i in range(num_processes):
        start = i * chunk_size + 1
        end = (i+1) * chunk_size + 1 if i < num_processes-1 else n+1
        results.append(pool.apply_async(createMatrixChunk, args=(start, end, n)))
    pool.close()
    pool.join()
    matrix = []
    for result in results:
        matrix += result.get()
    return np.array(matrix)
```

In this implementation, the `createMatrixChunk` function creates a chunk of the matrix from `start` to `end` rows. The `createMatrix` function splits the matrix creation into `num_processes` chunks and processes them in parallel using the `multiprocessing.Pool` class. The results from each process are collected and concatenated to form the final matrix.

You can adjust the `num_processes` parameter to control the number of processes used for parallel processing. Keep in mind that using too many processes can lead to diminishing returns due to overhead costs.

--------

## GPT3.5 Attempt \#1

Yes, you can speed up the creation of the matrix using multiprocessing. One way to do this is to split the matrix creation into multiple processes, each creating a portion of the matrix. Here's an example implementation using the `multiprocessing` module:

```
import numpy as np
import multiprocessing

def createMatrixChunk(start, end, n, queue):
    chunk = []
    for j in range(start, end):
        row = []
        for i in range(1, n+1):
            value = 1/(i+j-1)
            row.append(value)
        chunk.append(row)
    queue.put(chunk)

def createMatrix(n, num_processes):
    matrix = np.zeros((n, n))
    chunk_size = n // num_processes
    queue = multiprocessing.Queue()
    processes = []
    for i in range(num_processes):
        start = i * chunk_size
        end = start + chunk_size
        if i == num_processes - 1:
            end = n
        p = multiprocessing.Process(target=createMatrixChunk, args=(start, end, n, queue))
        p.start()
        processes.append(p)
    for p in processes:
        p.join()
    for i in range(num_processes):
        start = i * chunk_size
        end = start + chunk_size
        if i == num_processes - 1:
            end = n
        chunk = queue.get()
        matrix[start:end, :] = chunk
    return matrix
```

This implementation splits the matrix creation into `num_processes` processes, each creating a portion of the matrix. The `createMatrixChunk` function creates a chunk of the matrix, starting from row `start` and ending at row `end-1`, and puts it into a queue. The main process then waits for all the processes to finish, and retrieves the chunks from the queue and combines them into the final matrix.

To use this implementation, simply call `createMatrix(n, num_processes)` with the desired matrix size `n` and the number of processes to use `num_processes`. For example:

```
matrix = createMatrix(1000, 4)
```

This will create a 1000x1000 matrix using 4 processes. You can adjust the number of processes to find the optimal balance between speed and resource usage.

--------

## GPT3.5 Attempt \#2

Yes, you can speed up the creation of the matrix using multiprocessing. One way to do this is to split the matrix creation into multiple processes, where each process creates a subset of the rows of the matrix. Here's an example implementation using the `multiprocessing` module:

```
import numpy as np
import multiprocessing

def createMatrix(n):
    matrix = np.zeros((n, n))

    def createRow(i):
        row = []
        for j in range(1, n+1):
            value = 1/(i+j-1)
            row.append(value)
        return row

    with multiprocessing.Pool() as pool:
        rows = pool.map(createRow, range(1, n+1))

    for i, row in enumerate(rows):
        matrix[i] = row

    return matrix
```

In this implementation, the `createRow` function creates a single row of the matrix, and the `Pool.map` method is used to create all the rows in parallel. The resulting rows are then combined into the final matrix.

Note that the `multiprocessing` module can be sensitive to the size of the data being passed between processes, so you may need to experiment with different chunk sizes to find the optimal performance.

--------
