
# Post \#60279160 [Link](https://stackoverflow.com/questions/60279160/)

## Compare two dataframes Pyspark

**Vote**: 7 (449/702) **Views**: 68888 (127/702) 

**Internal ID** \#1-3-175

Created at 2020-02-18 10:50:32

Tags: `python` `dataframe` `apache-spark` `pyspark` `apache-spark-sql`

----------

#### Metadata:

Area: `Data Science & Machine Learning`

Language: `python` (full parsed tag list: `python`)

----------

**Notepad**


----------

I'm trying to compare two data frames with have same number of columns i.e. 4 columns with id as key column in both data frames

```
df1 = spark.read.csv("/path/to/data1.csv")
df2 = spark.read.csv("/path/to/data2.csv")
```


Now I want to append new column to DF2 i.e. column_names which is the list of the columns with different values than df1

```
df2.withColumn("column_names",udf())
```




```
+------+---------+--------+------+
|   id | |name  | sal  | Address |
+------+---------+--------+------+
|     1|  ABC   | 5000 | US      |
|     2|  DEF   | 4000 | UK      |
|     3|  GHI   | 3000 | JPN     |
|     4|  JKL   | 4500 | CHN     |
+------+---------+--------+------+
```




```
+------+---------+--------+------+
|   id | |name  | sal  | Address |
+------+---------+--------+------+
|     1|  ABC   | 5000 | US      |
|     2|  DEF   | 4000 | CAN     |
|     3|  GHI   | 3500 | JPN     |
|     4|  JKL_M | 4800 | CHN     |
+------+---------+--------+------+
```


Now I want DF3



```
+------+---------+--------+------+--------------+
|   id | |name  | sal  | Address | column_names |
+------+---------+--------+------+--------------+
|     1|  ABC   | 5000 | US      |  []          |
|     2|  DEF   | 4000 | CAN     |  [address]   |
|     3|  GHI   | 3500 | JPN     |  [sal]       |
|     4|  JKL_M | 4800 | CHN     |  [name,sal]  |
+------+---------+--------+------+--------------+
```


I saw this SO question, [How to compare two dataframe and print columns that are different in scala](https://stackoverflow.com/questions/44338412/how-to-compare-two-dataframe-and-print-columns-that-are-different-in-scala). Tried that, however the result is different.

I'm thinking of going with a UDF function by passing row from each dataframe to udf and compare column by column and return column list. However for that both the data frames should be in sorted order so that same id rows will be sent to udf. Sorting is costly operation here. Any solution?


----------
        
## GPT4 Attempt \#0

You can achieve this by using a combination of Spark SQL functions without the need for sorting or UDFs. Here is a step-by-step guide:

1. First, rename the columns in the second DataFrame to avoid column name clashes when joining:

```python
df2 = df2.select([col(c).alias(c + '_df2') for c in df2.columns])
```

2. Then, join the two DataFrames on the 'id' column:

```python
df = df1.join(df2, df1.id == df2.id_df2)
```

3. Now, create a new column 'column_names' that contains the names of the columns that have different values in the two DataFrames:

```python
from pyspark.sql import functions as F

df = df.withColumn("column_names", 
                   F.array([F.when(df[c] != df[c + '_df2'], F.lit(c)) for c in df1.columns if c != 'id']).cast("array<string>"))
```

4. Finally, select the columns you are interested in and rename them back to their original names:

```python
df = df.select([col(c).alias(c.replace('_df2', '')) for c in df2.columns] + ['column_names'])
```

This will give you the desired output. The advantage of this approach is that it avoids costly operations like sorting or UDFs, which can be slow on large datasets.

--------

## GPT4 Attempt \#1

You can achieve this by using PySpark's DataFrame transformations and a User Defined Function (UDF). Here's a step-by-step guide:

1. First, join the two dataframes on the 'id' column. This will allow you to compare the corresponding rows without needing to sort the dataframes.

```python
df = df1.join(df2, on='id', how='inner', suffixes=('_df1', '_df2'))
```

2. Define a UDF that takes two rows (one from each dataframe) and returns a list of column names where the values are different.

```python
from pyspark.sql.functions import udf
from pyspark.sql.types import ArrayType, StringType

def compare_rows(row1, row2):
    diff_cols = []
    for col_name in df1.columns:
        if row1[col_name] != row2[col_name]:
            diff_cols.append(col_name)
    return diff_cols

compare_rows_udf = udf(compare_rows, ArrayType(StringType()))
```

3. Apply the UDF to the joined dataframe to create the 'column_names' column.

```python
df = df.withColumn('column_names', compare_rows_udf(df['row_df1'], df['row_df2']))
```

4. Finally, drop the duplicate columns from the joined dataframe and rename the remaining columns to their original names.

```python
for col_name in df1.columns:
    df = df.drop(col_name + '_df1')
    df = df.withColumnRenamed(col_name + '_df2', col_name)
```

This will give you a dataframe where each row has an additional 'column_names' column that contains a list of column names where the values were different in the original dataframes.

Please note that this solution assumes that the 'id' column is unique in both dataframes. If this is not the case, you will need to handle duplicate 'id' values before joining the dataframes.

--------

## GPT4 Attempt \#2

You can use the `exceptAll` function to find the differences between two dataframes. However, this function will return the entire row if there is any difference in any column. To get the column names, you can use a UDF function. Here is a possible solution:

First, you need to join the two dataframes on the 'id' column:

```python
df = df1.join(df2, on=['id'], how='inner', suffixes=('_df1', '_df2'))
```

Then, define a UDF function to compare the columns:

```python
from pyspark.sql.functions import udf
from pyspark.sql.types import ArrayType, StringType

def compare_columns(row):
    diff_columns = []
    for column in df1.columns:
        if row[column + '_df1'] != row[column + '_df2']:
            diff_columns.append(column)
    return diff_columns

compare_columns_udf = udf(compare_columns, ArrayType(StringType()))
```

Finally, apply the UDF function to the joined dataframe:

```python
df = df.withColumn('column_names', compare_columns_udf(df))
```

This will add a new column 'column_names' to the dataframe, which contains a list of column names that have different values in df1 and df2.

Please note that this solution assumes that the 'id' column is unique in both dataframes. If it's not the case, you need to drop duplicates or aggregate the data before joining. Also, this solution does not handle null values. If your data can contain null values, you need to modify the UDF function to handle them.

--------
