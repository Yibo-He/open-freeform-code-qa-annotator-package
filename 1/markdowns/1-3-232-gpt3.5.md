
# Post \#54347963 [Link](https://stackoverflow.com/questions/54347963/)

## 'tf' is not defined on load_model() - using lambda

**Vote**: 20 (261/702) **Views**: 42285 (189/702) 

**Internal ID** \#1-3-232

Created at 2019-01-24 13:38:19

Tags: `python` `tensorflow` `lambda` `keras`

----------

#### Metadata:

Area: `Data Science & Machine Learning`

Language: `python` (full parsed tag list: `python`)

----------

**Notepad**


----------

I have a `Keras` model that I am trying to export and use in a different python code.

Here is my code:

```
from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM, GRU, Flatten, Dropout, Lambda
from keras.layers.embeddings import Embedding
import tensorflow as tf


EMBEDDING_DIM = 100

model = Sequential()
model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))
model.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))
model.add(Dense(8, input_dim=4, activation='relu'))
model.add(Dense(3, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train_pad, y_train, batch_size=128, epochs=25, validation_data=(X_val_pad, y_val), verbose=2)
model.save('my_model.h5')
```



---



In , when I import `my_model.h5` :

```
from keras.models import load_model
from keras.layers import Lambda
import tensorflow as tf


def learning(test_samples):
    model = load_model('my_model.h5')
    #ERROR HERE
    #rest of the code
```


The error is the following:

```
in <lambda>
    model.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))
NameError: name 'tf' is not defined
```


After research, I got that the fact that `lambda` is the reason for this problem, but I added these references and it didn't help:

```
from keras.models import load_model
from keras.layers import Lambda
import tensorflow as tf
```


What could be the problem?

Thank you


----------
        
## GPT3.5 Attempt \#0

The issue is that the `tf` module is not defined in the scope of the `Lambda` layer when you load the model. To fix this, you can add an import statement for `tf` in the file where you load the model:

```
from keras.models import load_model
from keras.layers import Lambda
import tensorflow as tf

def learning(test_samples):
    model = load_model('my_model.h5', custom_objects={'<lambda>': lambda x: tf.reduce_mean(x, axis=1)})
    # rest of the code
```

In the `load_model` function, you can pass a dictionary of custom objects to be used when loading the model. In this case, you can define a lambda function that performs the same operation as the `Lambda` layer in the original code, and pass it as a custom object with the name `<lambda>`. This will allow the model to be loaded correctly with the `Lambda` layer.

--------

## GPT3.5 Attempt \#1

The issue is that the `tf` module is not imported in the scope of the `Lambda` layer when you load the model. To fix this, you can add the following line of code before loading the model:

```
import tensorflow as tf
```

This will ensure that the `tf` module is available in the scope of the `Lambda` layer when you load the model. Your updated code should look like this:

```
from keras.models import load_model
from keras.layers import Lambda
import tensorflow as tf


def learning(test_samples):
    import tensorflow as tf # add this line
    model = load_model('my_model.h5')
    # rest of the code
```

--------

## GPT3.5 Attempt \#2

The issue is that the `tf` module is not defined in the scope of the `Lambda` layer when you load the model. You can fix this by importing `tf` in the same scope as the `Lambda` layer:

```
from keras.models import load_model
from keras.layers import Lambda
import tensorflow as tf


def learning(test_samples):
    # Import tf in the same scope as the Lambda layer
    model = load_model('my_model.h5', custom_objects={'tf': tf})
    # rest of the code
```

By passing `custom_objects={'tf': tf}` to `load_model`, you are telling Keras to use the `tf` module when it encounters the `Lambda` layer.

--------
