
# Post \#61000501 [Link](https://stackoverflow.com/questions/61000501/)

## Json serialization of nested dataclasses

**Vote**: 14 (336/702) **Views**: 14524 (365/702) 

**Internal ID** \#1-3-287

Created at 2020-04-02 20:25:24

Tags: `python` `python-dataclasses` `json-serialization`

----------

#### Metadata:

Area: `Data Science & Machine Learning`

Language: `python` (full parsed tag list: `python`)

----------

**Notepad**


----------

I would need to take the question about `json serialization of @dataclass` from [Make the Python json encoder support Python's new dataclasses](https://stackoverflow.com/questions/51286748/make-the-python-json-encoder-support-pythons-new-dataclasses)  a bit further: consider when they are in a nested structure. 

Consider:

```
import json
from attr import dataclass
from dataclasses_json import dataclass_json
@dataclass
@dataclass_json
class Prod:
    id: int
    name: str
    price: float

prods = [Prod(1,'A',25.3),Prod(2,'B',79.95)]
pjson = json.dumps(prods)
```


That gives us:

```
TypeError: Object of type Prod is not JSON serializable
```


Note the above does incorporate one of the answers [https://stackoverflow.com/a/59688140/1056563](https://stackoverflow.com/a/59688140/1056563) . It  claims to support the nested case via the `dataclass_json` decorator . Apparently that does not actually work. 

I also tried another of the answers [https://stackoverflow.com/a/51286749/1056563](https://stackoverflow.com/a/51286749/1056563) :

```
class EnhancedJSONEncoder(json.JSONEncoder):
        def default(s, o):
            if dataclasses.is_dataclass(o):
                return dataclasses.asdict(o)
            return super().default(o)
```


And I created a helper method for it:

```
def jdump(s,foo):
    return json.dumps(foo, cls=s.c.EnhancedJSONEncoder)
```


But using that method also did not effect the (error) result.  Any further tips?


----------
        
## GPT3.5 Attempt \#0

The issue with the code you provided is that the `dataclass_json` decorator only adds methods to the class to serialize and deserialize the object to and from JSON. It does not actually change the behavior of the `json.dumps` function.

To serialize a nested structure of dataclasses, you can modify the `default` method of the `json.JSONEncoder` class to handle dataclasses. Here's an example implementation:

```
import json
from dataclasses import dataclass
from dataclasses_json import dataclass_json

@dataclass_json
@dataclass
class Prod:
    id: int
    name: str
    price: float

prods = [Prod(1,'A',25.3),Prod(2,'B',79.95)]

class DataclassEncoder(json.JSONEncoder):
    def default(self, obj):
        if hasattr(obj, 'to_dict'):
            return obj.to_dict()
        elif isinstance(obj, list):
            return [self.default(item) for item in obj]
        else:
            return super().default(obj)

pjson = json.dumps(prods, cls=DataclassEncoder)
print(pjson)
```

In this implementation, we define a custom `DataclassEncoder` class that inherits from `json.JSONEncoder`. We override the `default` method to check if the object being serialized has a `to_dict` method (which is added by the `dataclass_json` decorator). If it does, we call that method to get a dictionary representation of the object. If the object is a list, we recursively call `default` on each item in the list. Otherwise, we fall back to the default behavior of `json.JSONEncoder`.

With this implementation, we can now serialize a nested structure of dataclasses to JSON:

```
@dataclass_json
@dataclass
class Order:
    id: int
    customer: str
    products: List[Prod]

order = Order(1, 'John Doe', prods)
ojson = json.dumps(order, cls=DataclassEncoder)
print(ojson)
```

Output:
```
{"id": 1, "customer": "John Doe", "products": [{"id": 1, "name": "A", "price": 25.3}, {"id": 2, "name": "B", "price": 79.95}]}
```

--------

## GPT3.5 Attempt \#1

The issue with the code you provided is that the `dataclass_json` decorator only adds methods to serialize and deserialize the dataclass to and from JSON, but it does not actually register the class with the JSON encoder. Therefore, when you try to serialize a list of `Prod` objects, the JSON encoder does not know how to handle them.

To solve this issue, you can create a custom JSON encoder that checks if an object is a dataclass and serializes it using the `asdict` function from the `dataclasses` module. Here's an example:

```
import json
from dataclasses import asdict, is_dataclass

class DataclassEncoder(json.JSONEncoder):
    def default(self, obj):
        if is_dataclass(obj):
            return asdict(obj)
        return super().default(obj)

prods = [Prod(1,'A',25.3),Prod(2,'B',79.95)]
pjson = json.dumps(prods, cls=DataclassEncoder)
```

In this example, we define a custom JSON encoder called `DataclassEncoder` that inherits from `json.JSONEncoder`. We override the `default` method, which is called by the encoder when it encounters an object it does not know how to serialize.

In our implementation of `default`, we first check if the object is a dataclass using the `is_dataclass` function. If it is, we serialize it using the `asdict` function from the `dataclasses` module. Otherwise, we call the `default` method of the parent class to handle the serialization.

Finally, we pass an instance of `DataclassEncoder` to the `cls` parameter of the `json.dumps` function to use our custom encoder for serialization.

--------

## GPT3.5 Attempt \#2

To serialize nested dataclasses, you can modify the `default` method of the `EnhancedJSONEncoder` class to recursively serialize any nested dataclasses. Here's an updated version of the `EnhancedJSONEncoder` class:

```
class EnhancedJSONEncoder(json.JSONEncoder):
    def default(self, o):
        if dataclasses.is_dataclass(o):
            return dataclasses.asdict(o, dict_factory=dict)
        elif isinstance(o, (list, tuple)):
            return [self.default(item) for item in o]
        elif isinstance(o, dict):
            return {key: self.default(value) for key, value in o.items()}
        return super().default(o)
```

This implementation checks if the object is a dataclass and serializes it using `dataclasses.asdict`. If the object is a list, tuple, or dictionary, it recursively serializes each item in the container. Finally, if the object is not a dataclass or container, it falls back to the default serialization behavior.

You can use this updated `EnhancedJSONEncoder` class with your `jdump` method to serialize nested dataclasses:

```
def jdump(foo):
    return json.dumps(foo, cls=EnhancedJSONEncoder)
```

With these changes, you should be able to serialize nested dataclasses without encountering the `TypeError`.

--------
