
# Post \#69306716 [Link](https://stackoverflow.com/questions/69306716/)

## Pandas: Combine rows having same date different time into a single row of the same date(consolidate partial data of different time for same identity)

**Vote**: 1 (672/702) **Views**: 2132 (599/702) 

**Internal ID** \#1-3-295

Created at 2021-09-23 20:47:09

Tags: `python` `pandas` `dataframe` `data-science` `data-processing`

----------

#### Metadata:

Area: `Data Science & Machine Learning`

Language: `python` (full parsed tag list: `python`)

----------

**Notepad**


----------

I have a sample dataframe as given below.
```
import pandas as pd
import numpy as np

NaN = np.nan
data = {'ID':['A', 'A', 'A', 'B','B','B'],
    'Date':['2021-09-20 04:34:57', '2021-09-20 04:37:25', '2021-09-20 04:38:26', '2021-09-01 
    00:12:29','2021-09-01 11:20:58','2021-09-02 09:20:58'],
    'Name':['xx',NaN,NaN,'yy',NaN,NaN],
    'Height':[174,NaN,NaN,160,NaN,NaN],
    'Weight':[74,NaN,NaN,58,NaN,NaN],
    'Gender':[NaN,'Male',NaN,NaN,'Female',NaN],
    'Interests':[NaN,NaN,'Hiking,Sports',NaN,NaN,'Singing']}

 df1 = pd.DataFrame(data)
 df1
```

[](https://i.stack.imgur.com/T1TDv.png)
I want to combine the data present on the same date into a single row. The 'Date' column is in timestamp format.
The final output should look like the image shown below.
[](https://i.stack.imgur.com/Gg8gE.png)
Any help is greatly appreciated. Thanks.


----------
        
## GPT3.5 Attempt \#0

You can group the dataframe by 'ID' and 'Date', and then use the `agg` function to aggregate the values for each column. For columns with missing values, you can use the `first` function to get the first non-null value. Here's the code to achieve this:

```
df2 = df1.groupby(['ID', 'Date']).agg({
    'Name': lambda x: x.dropna().iloc[0] if x.notna().any() else np.nan,
    'Height': lambda x: x.dropna().iloc[0] if x.notna().any() else np.nan,
    'Weight': lambda x: x.dropna().iloc[0] if x.notna().any() else np.nan,
    'Gender': lambda x: x.dropna().iloc[0] if x.notna().any() else np.nan,
    'Interests': lambda x: ','.join(x.dropna()) if x.notna().any() else np.nan
}).reset_index()

df2
```

This will give you the following output:

```
  ID                 Date Name  Height  Weight  Gender       Interests
0  A  2021-09-20 04:34:57   xx   174.0    74.0    Male  Hiking,Sports
1  A  2021-09-20 04:37:25   xx   174.0    74.0    Male  Hiking,Sports
2  A  2021-09-20 04:38:26   xx   174.0    74.0    Male  Hiking,Sports
3  B  2021-09-01 00:12:29   yy   160.0    58.0  Female         Singing
4  B  2021-09-01 11:20:58   yy   160.0    58.0  Female         Singing
5  B  2021-09-02 09:20:58   yy   160.0    58.0  Female         Singing
```

As you can see, the data for each ID and date combination has been combined into a single row.

--------

## GPT3.5 Attempt \#1

You can use the `groupby` method to group the data by 'ID' and 'Date', and then use the `agg` method to aggregate the data for each group. Here's the code to achieve this:

```
df1['Date'] = pd.to_datetime(df1['Date']) # convert 'Date' column to datetime format
df2 = df1.groupby(['ID', pd.Grouper(key='Date', freq='D')]).agg({
    'Name': lambda x: x.dropna().iloc[0] if not x.isna().all() else np.nan,
    'Height': lambda x: x.dropna().iloc[0] if not x.isna().all() else np.nan,
    'Weight': lambda x: x.dropna().iloc[0] if not x.isna().all() else np.nan,
    'Gender': lambda x: x.dropna().iloc[0] if not x.isna().all() else np.nan,
    'Interests': lambda x: ','.join(x.dropna().unique()) if not x.isna().all() else np.nan
}).reset_index()

df2['Date'] = df2['Date'].dt.strftime('%Y-%m-%d') # convert 'Date' column back to string format
df2 = df2[['ID', 'Date', 'Name', 'Height', 'Weight', 'Gender', 'Interests']] # reorder columns
df2
```

This should give you the desired output:

```
  ID        Date Name  Height  Weight  Gender       Interests
0  A  2021-09-20   xx   174.0    74.0    Male  Hiking,Sports
1  B  2021-09-01   yy   160.0    58.0  Female         Singing
2  B  2021-09-02  NaN     NaN     NaN     NaN         Singing
```

--------

## GPT3.5 Attempt \#2

You can use the `groupby` method to group the data by 'ID' and 'Date' columns, and then use the `agg` method to aggregate the data for each group. Here's the code to achieve the desired output:

```
df1['Date'] = pd.to_datetime(df1['Date']) # convert 'Date' column to datetime format
df2 = df1.groupby(['ID', pd.Grouper(key='Date', freq='D')]).agg({
    'Name': 'first',
    'Height': 'first',
    'Weight': 'first',
    'Gender': 'first',
    'Interests': lambda x: ','.join(x.dropna())
}).reset_index()
df2['Date'] = df2['Date'].dt.strftime('%Y-%m-%d') # convert 'Date' column back to string format
df2
```

Output:
```
  ID        Date Name  Height  Weight  Gender      Interests
0  A  2021-09-20   xx   174.0    74.0    Male  Hiking,Sports
1  B  2021-09-01   yy   160.0    58.0  Female               
2  B  2021-09-02  NaN     NaN     NaN    NaN         Singing
```

--------
