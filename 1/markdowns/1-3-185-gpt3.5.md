
# Post \#60145306 [Link](https://stackoverflow.com/questions/60145306/)

## Remove background text and noise from an image using image processing with OpenCV

**Vote**: 11 (370/702) **Views**: 17358 (329/702) 

**Internal ID** \#1-3-185

Created at 2020-02-10 06:45:51

Tags: `python` `image` `opencv` `image-processing` `computer-vision`

----------

#### Metadata:

Area: `Data Science & Machine Learning`

Language: `python` (full parsed tag list: `python`)

----------

**Notepad**


----------

I have these images

[](https://i.stack.imgur.com/VOfgD.png)

[](https://i.stack.imgur.com/TdRKg.png)

For which I want to remove the text in the background. Only the `captcha characters` should remain(i.e K6PwKA, YabVzu). The task is to identify these characters later using tesseract.

This is what I have tried, but it isn't giving much good accuracy.

```
import cv2
import pytesseract

pytesseract.pytesseract.tesseract_cmd = r"C:\Users\HPO2KOR\AppData\Local\Tesseract-OCR\tesseract.exe"
img = cv2.imread("untitled.png")
gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
gray_filtered = cv2.inRange(gray_image, 0, 75)
cv2.imwrite("cleaned.png", gray_filtered)
```


How can I improve the same?

 
I tried all the suggestion that I was getting for this question and none of them worked for me.

 
According to Elias, I tried finding the color of the captcha text using photoshop by converting it to grayscale which came out to be somewhere in between [100, 105]. I then threshold the image based on this range. But the result which I got did not give satisfactory result from tesseract.

```
gray_filtered = cv2.inRange(gray_image, 100, 105)
cv2.imwrite("cleaned.png", gray_filtered)
gray_inv = ~gray_filtered
cv2.imwrite("cleaned.png", gray_inv)
data = pytesseract.image_to_string(gray_inv, lang='eng')
```


Output :

```
'KEP wKA'
```


Result : 

[](https://i.stack.imgur.com/AqYeO.png)



```
def get_text(img_name):
    lower = (100, 100, 100)
    upper = (104, 104, 104) 
    img = cv2.imread(img_name)
    img_rgb_inrange = cv2.inRange(img, lower, upper)
    neg_rgb_image = ~img_rgb_inrange
    cv2.imwrite('neg_img_rgb_inrange.png', neg_rgb_image)
    data = pytesseract.image_to_string(neg_rgb_image, lang='eng')
    return data
```


gives : 

[](https://i.stack.imgur.com/rSrSz.png)

and the text as

```
GXuMuUZ
```


Is there any way to soften it a little


----------
        
## GPT3.5 Attempt \#0

Yes, you can try applying some image processing techniques to improve the accuracy of the OCR. Here are some suggestions:

1. Apply image dilation: You can try applying dilation to the binary image to thicken the characters and make them more prominent. This can be done using the `cv2.dilate()` function. Here's an example:

```
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
dilated = cv2.dilate(gray_filtered, kernel, iterations=1)
cv2.imwrite("dilated.png", dilated)
```

2. Apply image smoothing: You can try applying some smoothing filters to the image to reduce noise and make the characters more distinct. This can be done using functions like `cv2.medianBlur()` or `cv2.GaussianBlur()`. Here's an example:

```
blurred = cv2.GaussianBlur(gray_filtered, (3,3), 0)
cv2.imwrite("blurred.png", blurred)
```

3. Try different thresholding methods: You can experiment with different thresholding methods to find the one that works best for your images. Some options include `cv2.THRESH_BINARY`, `cv2.THRESH_BINARY_INV`, `cv2.THRESH_TRUNC`, etc. Here's an example:

```
ret, thresh = cv2.threshold(gray_image, 100, 255, cv2.THRESH_BINARY_INV)
cv2.imwrite("thresh.png", thresh)
```

4. Use image segmentation: You can try segmenting the image into individual characters using techniques like contour detection or connected component analysis. This can help isolate the characters and improve the accuracy of the OCR. Here's an example:

```
contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
for cnt in contours:
    x,y,w,h = cv2.boundingRect(cnt)
    roi = gray_image[y:y+h, x:x+w]
    cv2.imwrite("char_{}.png".format(x), roi)
```

These are just some suggestions to get you started. You may need to experiment with different combinations of techniques to find the best approach for your specific images.

--------

## GPT3.5 Attempt \#1

One way to improve the accuracy of the OCR is to preprocess the image before applying the OCR. Here are some suggestions:

1. Apply a blur filter to the image to remove noise and smooth out the edges of the characters. You can use the `cv2.GaussianBlur()` function for this.

2. Apply a threshold to the image to convert it to a binary image. This will make it easier for the OCR to identify the characters. You can use the `cv2.threshold()` function for this.

3. Apply some morphological operations to the image to remove any small holes or gaps in the characters. You can use the `cv2.erode()` and `cv2.dilate()` functions for this.

Here's an example code that applies these steps:

```
import cv2
import pytesseract

pytesseract.pytesseract.tesseract_cmd = r"C:\Users\HPO2KOR\AppData\Local\Tesseract-OCR\tesseract.exe"

# Load the image
img = cv2.imread("untitled.png")

# Convert to grayscale
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Apply a blur filter
blur = cv2.GaussianBlur(gray, (5, 5), 0)

# Apply a threshold
_, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV+cv2.THRESH_OTSU)

# Apply some morphological operations
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
thresh = cv2.erode(thresh, kernel, iterations=1)
thresh = cv2.dilate(thresh, kernel, iterations=1)

# Save the preprocessed image
cv2.imwrite("preprocessed.png", thresh)

# Apply OCR
data = pytesseract.image_to_string(thresh, lang='eng')

# Print the result
print(data)
```

You can adjust the parameters of the blur filter, threshold, and morphological operations to get better results.

--------

## GPT3.5 Attempt \#2

One way to improve the accuracy of the OCR is to preprocess the image before passing it to tesseract. Here are some suggestions:

1. Apply image smoothing: You can use a Gaussian blur or median blur to remove noise and smooth out the image. This can help improve the accuracy of the OCR.

```
gray_filtered = cv2.inRange(gray_image, 100, 105)
gray_filtered = cv2.medianBlur(gray_filtered, 3)
cv2.imwrite("cleaned.png", gray_filtered)
```

2. Apply image dilation: You can use image dilation to thicken the characters and make them more prominent. This can help improve the accuracy of the OCR.

```
gray_filtered = cv2.inRange(gray_image, 100, 105)
gray_filtered = cv2.medianBlur(gray_filtered, 3)
kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (3,3))
gray_filtered = cv2.dilate(gray_filtered, kernel, iterations=1)
cv2.imwrite("cleaned.png", gray_filtered)
```

3. Use adaptive thresholding: Instead of using a fixed threshold value, you can use adaptive thresholding to automatically determine the threshold value based on the local pixel intensity. This can help improve the accuracy of the OCR.

```
gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
gray_filtered = cv2.adaptiveThreshold(gray_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
cv2.imwrite("cleaned.png", gray_filtered)
```

You can try these preprocessing techniques and see if they improve the accuracy of the OCR.

--------
