
# Post \#65429877 [Link](https://stackoverflow.com/questions/65429877/)

## AWS Lambda Container Running Selenium With Headless Chrome Works Locally But Not In AWS Lambda

**Vote**: 15 (318/702) **Views**: 9764 (420/702) 

**Internal ID** \#1-3-199

Created at 2020-12-23 19:25:28

Tags: `python` `docker` `selenium` `aws-lambda` `chromium`

----------

#### Metadata:

Area: `Data Science & Machine Learning`

Language: `python` (full parsed tag list: `python`)

----------

**Notepad**


----------

I am currently developing a Python program which has a segment which uses a headless version of Chrome and Selenium to perform a repetitive process. I am aiming to run the program on Lambda.
The overall program has around 1GB of dependencies so the option to use the standard method of using a [.zip archive](https://docs.aws.amazon.com/lambda/latest/dg/python-package.html), containing all my function code and dependencies is not an option as the total unzipped size of the function and all layers can't exceed the unzipped deployment package size limit of 250 MB.
So, that is where the new [AWS Lambda – Container Image Support](https://aws.amazon.com/blogs/aws/new-for-aws-lambda-container-image-support/) (I used this linked tutorial to develop this whole implementation so please read if you need more info) comes in. This allows me to package and deploy my Lambda function as container images of up to 10 GB in size.
I am using the base image hosted in ECR Public provided by AWS which runs Amazon Linux 2. Firstly - in my Dockerfile I:
- - - - - 
and finally - I install both Chrome (87.0.4280.88 at the time of reading) and Chromedriver (87.0.4280.88)
- 
there is a possibility this could be where the problem lies, but I highly doubt this as both are the same version - [ChromeDriver uses the same version number scheme as Chrome](https://www.chromium.org/developers/version-numbers).
This is my :
```
# 1) DOWNLOAD BASE IMAGE.
FROM public.ecr.aws/lambda/python:3.8

# 2) DEFINE GLOBAL ARGS.
ARG MAIN_FILE="main.py"
ARG ENV_FILE="params.env"
ARG REQUIREMENTS_FILE="requirements.txt"
ARG FUNCTION_ROOT="."
ARG RUNTIME_VERSION="3.8"

# 3) COPY FILES.
# Copy The Main .py File.
COPY ${MAIN_FILE} ${LAMBDA_TASK_ROOT}
# Copy The .env File.
COPY ${ENV_FILE} ${LAMBDA_TASK_ROOT}
# Copy The requirements.txt File.
COPY ${REQUIREMENTS_FILE} ${LAMBDA_TASK_ROOT}
# Copy Helpers Folder.
COPY helpers/ ${LAMBDA_TASK_ROOT}/helpers/
# Copy Private Folder.
COPY priv/ ${LAMBDA_TASK_ROOT}/priv/
# Copy Source Data Folder.
COPY source_data/ ${LAMBDA_TASK_ROOT}/source_data/

# 4) INSTALL DEPENDENCIES.
RUN --mount=type=cache,target=/root/.cache/pip python3.8 -m pip install --upgrade pip
RUN --mount=type=cache,target=/root/.cache/pip python3.8 -m pip install wheel
RUN --mount=type=cache,target=/root/.cache/pip python3.8 -m pip install urllib3
RUN --mount=type=cache,target=/root/.cache/pip python3.8 -m pip install -r requirements.txt --default-timeout=100

# 5) DOWNLOAD & INSTALL CHROMEIUM + CHROMEDRIVER.
#RUN yum -y upgrade
RUN yum -y install wget unzip libX11 nano wget unzip xorg-x11-xauth xclock xterm

# Install Chrome
RUN wget https://intoli.com/install-google-chrome.sh
RUN bash install-google-chrome.sh

# Install Chromedriver
RUN wget https://chromedriver.storage.googleapis.com/87.0.4280.88/chromedriver_linux64.zip
RUN unzip ./chromedriver_linux64.zip
RUN rm ./chromedriver_linux64.zip
RUN mv -f ./chromedriver /usr/local/bin/chromedriver
RUN chmod 755 /usr/local/bin/chromedriver

# 5) SET CMD OF HANDLER.
CMD [ "main.lambda_handler" ]
```

This image always builds without a problem and creates my image as expected.
and my  file:
```
version: "3.7"
services:
  lambda:
    image: tbg-lambda:latest
    build: .
    ports:
      - "8080:8080"
    env_file:
     - ./params.env
```

So - now that the image is build I can test locally with cURL. Here, I am passing an empty JSON payload:
```
curl -XPOST "http://localhost:8080/2015-03-31/functions/function/invocations" -d '{}'
```

which runs the whole program perfectly start to end using Chrome headless mode with no errors.
So great - the Docker container works locally and as expected.
Lets upload it to ECR so I can use it with my Lambda Function (ECR URL changed for security):
```
aws ecr create-repository --repository-name tbg-lambda:latest --image-scanning-configuration scanOnPush=true
docker tag tbg-lambda:latest 123412341234.dkr.ecr.sa-east-1.amazonaws.com/tbg-lambda:latest
aws ecr get-login-password | docker login --username AWS --password-stdin 123412341234.dkr.ecr.sa-east-1.amazonaws.com
docker push 123412341234.dkr.ecr.sa-east-1.amazonaws.com/tbg-lambda:latest
```

Everything pushes up as expected - I then create my new lambda function, choosing "Container Image" as the function option and attach the IAM role with all the permissions I need:
[](https://i.stack.imgur.com/pNZnU.png)
I have the memory set the max value just to ensure this isn't the problem:
[](https://i.stack.imgur.com/1pUO5.png)
Ok - so lets to get to the 
I use a test event to invoke the function through the console:
[](https://i.stack.imgur.com/kKHzm.png)
Everything runs perfectly until it hits the code which creates the webdriver driver with Chrome:
```
options = Options()
    options.add_argument('--no-sandbox')
    options.add_argument('--headless')
    options.add_argument('--single-process')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--remote-debugging-port=9222')
    options.add_argument('--disable-infobars')
    driver = webdriver.Chrome(
        service_args=["--verbose", "--log-path={}".format(logPath)],
        executable_path=f"/usr/local/bin/chromedriver",
        options=options
    )
```

PS: logPath is just another folder in the project directory - the logs output here as expected, the logs are shown below.

```
Caught WebDriverException Error: unknown error: Chrome failed to start: crashed.

(unknown error: DevToolsActivePort file doesn't exist)

(The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)

END RequestId: 7c933bca-5f0d-4458-9529-db28da677444

REPORT RequestId: 7c933bca-5f0d-4458-9529-db28da677444 Duration: 59104.94 ms Billed Duration: 59105 ms Memory Size: 10240 MB Max Memory Used: 481 MB

RequestId: 7c933bca-5f0d-4458-9529-db28da677444 Error: Runtime exited with error: exit status 1 Runtime.ExitError
```


```
[1608748453.064][INFO]: Starting ChromeDriver 87.0.4280.88 (89e2380a3e36c3464b5dd1302349b1382549290d-refs/branch-heads/4280@{#1761}) on port 54581
[1608748453.064][INFO]: Please see https://chromedriver.chromium.org/security-considerations for suggestions on keeping ChromeDriver safe.
[1608748453.064][INFO]: /dev/shm not writable, adding --disable-dev-shm-usage switch
[1608748453.679][SEVERE]: CreatePlatformSocket() failed: Address family not supported by protocol (97)
[1608748453.679][INFO]: listen on IPv6 failed with error ERR_ADDRESS_UNREACHABLE
[1608748454.432][INFO]: [13826d22c628514ca452d1f2949eb011] COMMAND InitSession {
   "capabilities": {
      "alwaysMatch": {
         "browserName": "chrome",
         "goog:chromeOptions": {
            "args": [ "--no-sandbox", "--headless", "--single-process", "--disable-dev-shm-usage" ],
            "extensions": [  ]
         },
         "platformName": "any"
      },
      "firstMatch": [ {

      } ]
   },
   "desiredCapabilities": {
      "browserName": "chrome",
      "goog:chromeOptions": {
         "args": [ "--no-sandbox", "--headless", "--single-process", "--disable-dev-shm-usage" ],
         "extensions": [  ]
      },
      "platform": "ANY",
      "version": ""
   }
}
[1608748454.433][INFO]: Populating Preferences file: {
   "alternate_error_pages": {
      "enabled": false
   },
   "autofill": {
      "enabled": false
   },
   "browser": {
      "check_default_browser": false
   },
   "distribution": {
      "import_bookmarks": false,
      "import_history": false,
      "import_search_engine": false,
      "make_chrome_default_for_user": false,
      "skip_first_run_ui": true
   },
   "dns_prefetching": {
      "enabled": false
   },
   "profile": {
      "content_settings": {
         "pattern_pairs": {
            "https://*,*": {
               "media-stream": {
                  "audio": "Default",
                  "video": "Default"
               }
            }
         }
      },
      "default_content_setting_values": {
         "geolocation": 1
      },
      "default_content_settings": {
         "geolocation": 1,
         "mouselock": 1,
         "notifications": 1,
         "popups": 1,
         "ppapi-broker": 1
      },
      "password_manager_enabled": false
   },
   "safebrowsing": {
      "enabled": false
   },
   "search": {
      "suggest_enabled": false
   },
   "translate": {
      "enabled": false
   }
}
[1608748454.433][INFO]: Populating Local State file: {
   "background_mode": {
      "enabled": false
   },
   "ssl": {
      "rev_checking": {
         "enabled": false
      }
   }
}
[1608748454.433][INFO]: Launching chrome: /usr/bin/google-chrome --disable-background-networking --disable-client-side-phishing-detection --disable-default-apps --disable-dev-shm-usage --disable-hang-monitor --disable-popup-blocking --disable-prompt-on-repost --disable-sync --enable-automation --enable-blink-features=ShadowDOMV0 --enable-logging --headless --log-level=0 --no-first-run --no-sandbox --no-service-autorun --password-store=basic --remote-debugging-port=0 --single-process --test-type=webdriver --use-mock-keychain --user-data-dir=/tmp/.com.google.Chrome.xgjs0h data:,
mkdir: cannot create directory ‘/.local’: Read-only file system
touch: cannot touch ‘/.local/share/applications/mimeapps.list’: No such file or directory
/usr/bin/google-chrome: line 45: /dev/fd/62: No such file or directory
/usr/bin/google-chrome: line 46: /dev/fd/62: No such file or directory
prctl(PR_SET_NO_NEW_PRIVS) failed
[1223/183429.578846:FATAL:zygote_communication_linux.cc(255)] Cannot communicate with zygote
Failed to generate minidump.[1608748469.769][INFO]: [13826d22c628514ca452d1f2949eb011] RESPONSE InitSession ERROR unknown error: Chrome failed to start: crashed.
  (unknown error: DevToolsActivePort file doesn't exist)
  (The process started from chrome location /usr/bin/google-chrome is no longer running, so ChromeDriver is assuming that Chrome has crashed.)
[1608748469.769][DEBUG]: Log type 'driver' lost 0 entries on destruction
[1608748469.769][DEBUG]: Log type 'browser' lost 0 entries on destruction
```

One thing that I might think could be the problem would the way lambda is running this container vs how I am running it locally.
Alot of people reccomend  to not run chrome as root - so is Lambda running the container as root and thats what is causing this? If so how can I tell Lambda or Docker to run the code as a non-root user.
This is mentioned here: [https://github.com/heroku/heroku-buildpack-google-chrome/issues/46#issuecomment-484562558](https://github.com/heroku/heroku-buildpack-google-chrome/issues/46#issuecomment-484562558)
I have been fighting with this error pretty much since AWS announced the lambda containers so any help with this would be brilliant  Please ask for any more info if I missed something!
Thanks in advance.


----------
        
## GPT4 Attempt \#0

The problem you're encountering is due to the fact that AWS Lambda runs your code in a read-only file system, with the exception of the /tmp directory. This is why you're seeing errors like "mkdir: cannot create directory ‘/.local’: Read-only file system".

The Chrome browser, when launched, tries to write to certain directories and files which are not writable in the AWS Lambda environment, hence the crash.

To solve this, you can use a custom build of Chrome that is specifically designed to run on AWS Lambda. This build is configured to write only to directories that are writable in the Lambda environment.

Here's how you can modify your Dockerfile to use this custom build of Chrome:

1. Remove the steps that download and install Chrome and Chromedriver.

2. Add these steps to download and install the custom build of Chrome and its corresponding Chromedriver:

```Dockerfile
# Download and install Chrome for AWS Lambda
RUN curl -SL https://github.com/adieuadieu/serverless-chrome/releases/download/v1.0.0-55/stable-headless-chromium-amazonlinux-2017-03.zip > headless-chromium.zip && \
    unzip headless-chromium.zip && \
    rm headless-chromium.zip && \
    mv headless-chromium /usr/local/bin/chrome

# Download and install Chromedriver that is compatible with the custom build of Chrome
RUN curl -SL https://chromedriver.storage.googleapis.com/2.37/chromedriver_linux64.zip > chromedriver.zip && \
    unzip chromedriver.zip && \
    rm chromedriver.zip && \
    mv chromedriver /usr/local/bin/chromedriver
```

3. Modify your Python code to use the custom build of Chrome:

```python
options = Options()
options.binary_location = '/usr/local/bin/chrome'
options.add_argument('--headless')
options.add_argument('--no-sandbox')
options.add_argument('--disable-gpu')
options.add_argument('--window-size=1280x1696')
options.add_argument('--user-data-dir=/tmp/user-data')
options.add_argument('--hide-scrollbars')
options.add_argument('--enable-logging')
options.add_argument('--log-level=0')
options.add_argument('--v=99')
options.add_argument('--single-process')
options.add_argument('--data-path=/tmp/data-path')
options.add_argument('--ignore-certificate-errors')
options.add_argument('--homedir=/tmp')
options.add_argument('--disk-cache-dir=/tmp/cache-dir')
options.add_argument('--remote-debugging-port=9222')
options.add_argument('--media-cache-size=33554432')
options.add_argument('--disable-dev-shm-usage')
options.add_argument('--disable-software-rasterizer')
options.add_argument('--mute-audio')
options.add_argument('--ignore-certificate-errors')
options.add_argument('--disable-setuid-sandbox')

driver = webdriver.Chrome(
    service_args=["--verbose", "--log-path={}".format(logPath)],
    executable_path='/usr/local/bin/chromedriver',
    options=options
)
```

This should solve the problem and allow your code to run on AWS Lambda.

--------

## GPT4 Attempt \#1

It seems like the issue is related to the way AWS Lambda runs the container. AWS Lambda runs the container as a non-root user by default. This might be causing the issue as Chrome requires certain permissions to run properly.

Here are a few things you can try:

1. Use a custom user in your Dockerfile: You can create a custom user in your Dockerfile and switch to that user before running your application. Here is an example:

```Dockerfile
# Create a group and user
RUN addgroup -g 1000 app && adduser -H -D -G app -u 1000 app

# Tell docker that all future commands should run as the app user
USER app
```

2. Use a different base image: You can try using a different base image that has the necessary permissions for Chrome to run properly. For example, you can use the selenium/standalone-chrome image which is designed to run Chrome and Chromedriver in a Docker container.

3. Use a different approach: Instead of running Chrome and Selenium directly in your Lambda function, you can use a service like AWS Fargate to run your Selenium tasks. This way, you can have more control over the environment and permissions.

4. Use a different tool: If you are using Selenium to scrape websites, you can consider using a different tool like Puppeteer which is a Node.js library to control headless Chrome or Chromium. Puppeteer works well in a Lambda environment and there are base Docker images available that are designed to run Puppeteer in AWS Lambda.

Remember to always test your changes locally using the AWS SAM CLI before deploying to AWS Lambda. This can help you catch issues early and speed up your development process.

--------

## GPT4 Attempt \#2

The error message "Cannot communicate with zygote" suggests that Chrome is having trouble starting up its sandbox environment. This is a common issue when trying to run Chrome in a Docker container, because the sandbox requires certain system capabilities that aren't available.

You're already using the `--no-sandbox` option, which should disable the sandbox and avoid this issue. However, you're also using the `--single-process` option, which is not recommended. According to the Chromium developers, the `--single-process` option is not well-supported, and can result in undefined behavior. It's possible that this is causing or contributing to the issue.

I would recommend removing the `--single-process` option from your code and trying again. If you're still having trouble, you might want to try using a different base image for your Docker container. The `public.ecr.aws/lambda/python:3.8` image is based on Amazon Linux 2, which might not have all the system libraries that Chrome needs. You could try using a base image that's known to work well with Chrome, such as `debian:buster` or `ubuntu:bionic`.

As for the question about running as root, AWS Lambda does indeed run your code as the root user inside the container. However, this shouldn't be a problem for Chrome, as long as you're using the `--no-sandbox` option. If you want to run your code as a non-root user anyway, you can do so by adding a `USER` directive to your Dockerfile. For example:

```
# Create a new user
RUN adduser --disabled-password --gecos '' myuser

# Switch to the new user
USER myuser
```

This will cause all subsequent `RUN`, `CMD`, and `ENTRYPOINT` directives to be run as the specified user. However, keep in mind that this user will not have root privileges, so you might need to adjust your Dockerfile and your code accordingly.

--------
