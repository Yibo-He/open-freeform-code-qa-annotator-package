
# Post \#54347963 [Link](https://stackoverflow.com/questions/54347963/)

## 'tf' is not defined on load_model() - using lambda

**Vote**: 20 (261/702) **Views**: 42285 (189/702) 

**Internal ID** \#1-3-232

Created at 2019-01-24 13:38:19

Tags: `python` `tensorflow` `lambda` `keras`

----------

#### Metadata:

Area: `Data Science & Machine Learning`

Language: `python` (full parsed tag list: `python`)

----------

**Notepad**


----------

I have a `Keras` model that I am trying to export and use in a different python code.

Here is my code:

```
from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM, GRU, Flatten, Dropout, Lambda
from keras.layers.embeddings import Embedding
import tensorflow as tf


EMBEDDING_DIM = 100

model = Sequential()
model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))
model.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))
model.add(Dense(8, input_dim=4, activation='relu'))
model.add(Dense(3, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train_pad, y_train, batch_size=128, epochs=25, validation_data=(X_val_pad, y_val), verbose=2)
model.save('my_model.h5')
```



---



In , when I import `my_model.h5` :

```
from keras.models import load_model
from keras.layers import Lambda
import tensorflow as tf


def learning(test_samples):
    model = load_model('my_model.h5')
    #ERROR HERE
    #rest of the code
```


The error is the following:

```
in <lambda>
    model.add(Lambda(lambda x: tf.reduce_mean(x, axis=1)))
NameError: name 'tf' is not defined
```


After research, I got that the fact that `lambda` is the reason for this problem, but I added these references and it didn't help:

```
from keras.models import load_model
from keras.layers import Lambda
import tensorflow as tf
```


What could be the problem?

Thank you


----------
        
## GPT4 Attempt \#0

The problem is that when you save the model, the custom lambda layer is saved without its context (i.e., the tensorflow library). When you load the model, it doesn't know what `tf` is, hence the error.

To solve this, you can define your lambda function as a standalone function and then use it in your model. This way, when you load the model, you can provide the function as a custom object.

Here is how you can do it:

First, define your lambda function as a standalone function:

```python
def reduce_mean(x):
    import tensorflow as tf
    return tf.reduce_mean(x, axis=1)
```

Then, use it in your model:

```python
model = Sequential()
model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))
model.add(Lambda(reduce_mean))
model.add(Dense(8, input_dim=4, activation='relu'))
model.add(Dense(3, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train_pad, y_train, batch_size=128, epochs=25, validation_data=(X_val_pad, y_val), verbose=2)
model.save('my_model.h5')
```

Finally, when you load the model, provide the function as a custom object:

```python
from keras.models import load_model

def reduce_mean(x):
    import tensorflow as tf
    return tf.reduce_mean(x, axis=1)

def learning(test_samples):
    model = load_model('my_model.h5', custom_objects={'reduce_mean': reduce_mean})
    #rest of the code
```

This way, the model knows what `tf.reduce_mean` is when it loads the model.

--------

## GPT4 Attempt \#1

The problem is that when you save the model, the custom objects (like the Lambda layer with the custom function) are not saved with it. So when you load the model, Keras doesn't know how to handle the Lambda layer.

To solve this, you need to provide the custom_objects argument to the load_model function, like this:

```python
from keras.models import load_model
import tensorflow as tf

def learning(test_samples):
    model = load_model('my_model.h5', custom_objects={'tf': tf, 'lambda': lambda x: tf.reduce_mean(x, axis=1)})
    #rest of the code
```

This tells Keras that when it encounters a Lambda layer, it should use the provided function (tf.reduce_mean in this case). 

Also, please note that you don't need to import Lambda from keras.layers in the second script, as you are not defining a new model there, just loading an existing one.

--------

## GPT4 Attempt \#2

The problem is that when you save the model, the custom lambda layer is also saved. However, when you load the model, Keras doesn't know how to handle the custom layer. 

You need to provide a dictionary to the `load_model` function that maps the layer name to the function. Here is how you can do it:

```python
from keras.models import load_model
from keras.layers import Lambda
import tensorflow as tf

def learning(test_samples):
    model = load_model('my_model.h5', custom_objects={'<lambda>': lambda x: tf.reduce_mean(x, axis=1)})
    #rest of the code
```

In the `custom_objects` dictionary, the key should be the name of the layer (in this case `<lambda>`) and the value should be the function that the layer should perform.

However, it's not a good practice to use lambda functions in your model if you plan to save it and load it later. Instead, you should define a custom layer. Here is how you can do it:

```python
from keras.models import Sequential
from keras.layers import Dense, Embedding, LSTM, GRU, Flatten, Dropout, Layer
from keras.layers.embeddings import Embedding
import tensorflow as tf

class ReduceMeanLayer(Layer):
    def __init__(self, **kwargs):
        super(ReduceMeanLayer, self).__init__(**kwargs)

    def call(self, x):
        return tf.reduce_mean(x, axis=1)

    def get_config(self):
        base_config = super(ReduceMeanLayer, self).get_config()
        return dict(list(base_config.items()))

EMBEDDING_DIM = 100

model = Sequential()
model.add(Embedding(vocab_size, 300, weights=[embedding_matrix], input_length=max_length, trainable=False))
model.add(ReduceMeanLayer())
model.add(Dense(8, input_dim=4, activation='relu'))
model.add(Dense(3, activation='softmax'))
model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])
model.fit(X_train_pad, y_train, batch_size=128, epochs=25, validation_data=(X_val_pad, y_val), verbose=2)
model.save('my_model.h5')
```

And then, when you load the model:

```python
from keras.models import load_model
from keras.layers import Lambda
import tensorflow as tf

def learning(test_samples):
    model = load_model('my_model.h5', custom_objects={'ReduceMeanLayer': ReduceMeanLayer})
    #rest of the code
```

This way, you can avoid using lambda functions and make your model more portable.

--------
